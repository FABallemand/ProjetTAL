{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 17:59:54.563549: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-25 17:59:54.565018: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-25 17:59:54.591946: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-25 17:59:54.592462: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-25 17:59:55.051686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BILSTM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données d'entrainement\n",
    "train_data_complete = pd.read_csv(\"../data/allocine_genres_train.csv\", sep=\",\")\n",
    "train_data = train_data_complete[[\"titre\", \"synopsis\", \"genre\"]]\n",
    "\n",
    "# Données de test/validation\n",
    "test_data_complete = pd.read_csv(\"../data/allocine_genres_test.csv\", sep=\",\")\n",
    "test_data = test_data_complete[[\"titre\", \"synopsis\", \"genre\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('genre', axis=1)\n",
    "y = train_data['genre']\n",
    "\n",
    "# Initialize the RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "#ros = RandomUnderSampler(random_state=42)\n",
    "\n",
    "\n",
    "# Perform oversampling\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Convert the resampled data back to a DataFrame\n",
    "train_data = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='genre')], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lister les classes et leur associer un identifiant unique. (Utile pour le plongement des mots et pour l'entraînement du CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres: ['biopic', 'comédie', 'documentaire', 'drame', 'historique', 'horreur', 'policier', 'romance', 'science fiction']\n",
      "Nombre d'exemplaires: 4509\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'biopic': 0,\n",
       " 'comédie': 1,\n",
       " 'documentaire': 2,\n",
       " 'drame': 3,\n",
       " 'historique': 4,\n",
       " 'horreur': 5,\n",
       " 'policier': 6,\n",
       " 'romance': 7,\n",
       " 'science fiction': 8}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste des genres\n",
    "genre_name = sorted(train_data.genre.unique().flatten())\n",
    "print(\"Genres:\", genre_name)\n",
    "print(\"Nombre d'exemplaires:\", len(train_data))\n",
    "\n",
    "# Identifiant unique par genre\n",
    "genre_index = {genre_name[i]:i for i in range(len(genre_name))}\n",
    "genre_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remplacer les genres par la valeur numérique associée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Le Crime de l' Orient - Express</td>\n",
       "      <td>En visite à Istanbul , le célèbre détective be...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 hommes en colère</td>\n",
       "      <td>Un jeune homme d' origine modeste est accusé d...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Après moi le bonheur</td>\n",
       "      <td>Lorsque Marie-Laure , mère de quatre jeunes en...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Les Lumières de la ville</td>\n",
       "      <td>Un vagabond s’ éprend d’ une belle et jeune ve...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Les Chemins de la dignité</td>\n",
       "      <td>L' histoire vraie de Carl Brashear , premier A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             titre  \\\n",
       "0  Le Crime de l' Orient - Express   \n",
       "1              12 hommes en colère   \n",
       "2             Après moi le bonheur   \n",
       "3         Les Lumières de la ville   \n",
       "4        Les Chemins de la dignité   \n",
       "\n",
       "                                            synopsis  genre  \n",
       "0  En visite à Istanbul , le célèbre détective be...      6  \n",
       "1  Un jeune homme d' origine modeste est accusé d...      3  \n",
       "2  Lorsque Marie-Laure , mère de quatre jeunes en...      3  \n",
       "3  Un vagabond s’ éprend d’ une belle et jeune ve...      7  \n",
       "4  L' histoire vraie de Carl Brashear , premier A...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.replace({\"genre\": genre_index})\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data[[\"titre\", \"synopsis\"]],\n",
    "                                                    train_data[[\"genre\"]],\n",
    "                                                    test_size=0.001,\n",
    "                                                    random_state=12, # Random seed for shuffle\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On combine le titre et le synopsis pour pouvoir les vectoriser par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_titre = X_train.titre\n",
    "X_train = X_train_titre + \" \" + X_train.synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841     Tu mourras à 20 ans Soudan , province d’ Aljaz...\n",
       "2949    Tina L' histoire d' Anna Mae Bullock , promise...\n",
       "868     Fleur de Tonnerre En 1800 , la Bretagne est à ...\n",
       "1284    Les Profs 2 Les pires Profs de France débarque...\n",
       "1267    Le Char et l' olivier , une autre histoire de ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      genre\n",
       "841       3\n",
       "2949      0\n",
       "868       3\n",
       "1284      1\n",
       "1267      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4504,)\n",
      "(4504, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexation du Vocabulaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorizer(documents, max_voc_size=8000, max_seq_length= 200, batch_size=64):\n",
    "\tvectorizer = tf.keras.layers.TextVectorization(max_tokens=max_voc_size, output_sequence_length=max_seq_length)\n",
    "\t# Création du jeu de données à partir de X_train et constitution de lots de 128 instances\n",
    "\ttext_ds = tf.data.Dataset.from_tensor_slices(documents).batch(batch_size)\n",
    "\t# Création du vocabulaire à partir des données d'entrée\n",
    "\tvectorizer.adapt(text_ds)\n",
    "\treturn vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 17:59:56.669763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [4504]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = get_vectorizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "print(len(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'de', 'la', 'et', 'le', 'à', 'un', 'une', 'les']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte initial: Tina L' histoire d' Anna Mae Bullock , promise à l' humble carrière d' infirmière , qui , après sa rencontre avec Ike Turner et leur vie orageuse , va devenir la grande chanteuse de rock que l' on connait .\n",
      "Vocabulaire dans le texte (15 premiers items):\n",
      "1 [UNK]\n",
      "10 l\n",
      "65 histoire\n",
      "17 d\n",
      "792 anna\n",
      "6437 mae\n",
      "1 [UNK]\n",
      "1595 promise\n",
      "6 à\n",
      "10 l\n",
      "1 [UNK]\n",
      "238 carrière\n",
      "17 d\n",
      "2157 infirmière\n",
      "19 qui\n"
     ]
    }
   ],
   "source": [
    "print(\"Texte initial:\", X_train.iloc[1])\n",
    "output = vectorizer([X_train.iloc[1]])\n",
    "print(\"Vocabulaire dans le texte (15 premiers items):\")\n",
    "for v in output.numpy()[0, :15]:\n",
    "    print(v, vectorizer.get_vocabulary()[v])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de Plongements de Mots Pré-entraînés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('merci', 0.7507892847061157),\n",
       " ('bonsoir', 0.7450243830680847),\n",
       " ('votre', 0.5642200112342834),\n",
       " ('vous', 0.5538792014122009),\n",
       " ('remercier', 0.5396129488945007),\n",
       " ('avance', 0.5288880467414856),\n",
       " ('discuter', 0.5033395886421204),\n",
       " ('je', 0.49339333176612854),\n",
       " ('désoler', 0.4899965822696686),\n",
       " ('ici', 0.4887441396713257)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format(\"../embedding/frWiki_no_phrase_no_postag_700_cbow_cut100.bin\", binary=True, unicode_errors=\"ignore\")\n",
    "model.most_similar(\"bonjour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'</s>': 0,\n",
       " 'de': 1,\n",
       " 'la': 2,\n",
       " 'à': 3,\n",
       " 'le': 4,\n",
       " 'et': 5,\n",
       " 'être': 6,\n",
       " 'en': 7,\n",
       " 'les': 8,\n",
       " 'un': 9,\n",
       " 'une': 10,\n",
       " 'avoir': 11,\n",
       " 'il': 12,\n",
       " 'dans': 13,\n",
       " 'par': 14,\n",
       " 'catégorie': 15,\n",
       " 'pour': 16,\n",
       " 'sur': 17,\n",
       " 'que': 18,\n",
       " 'se': 19,\n",
       " 'qui': 20,\n",
       " 'des': 21,\n",
       " 'ce': 22,\n",
       " 'avec': 23,\n",
       " 'ne': 24,\n",
       " 'son': 25,\n",
       " 'an': 26,\n",
       " 'plus': 27,\n",
       " 'ou': 28,\n",
       " 'pas': 29,\n",
       " 'faire': 30,\n",
       " 'elle': 31,\n",
       " 'sa': 32,\n",
       " 'pouvoir': 33,\n",
       " 'pop': 34,\n",
       " 'premier': 35,\n",
       " 'mais': 36,\n",
       " 'comme': 37,\n",
       " 'cette': 38,\n",
       " 'français': 39,\n",
       " 'avancement': 40,\n",
       " 'ses': 41,\n",
       " 'je': 42,\n",
       " 'on': 43,\n",
       " 'deux': 44,\n",
       " 'france': 45,\n",
       " 'tout': 46,\n",
       " 'aussi': 47,\n",
       " 'lien': 48,\n",
       " 'grand': 49,\n",
       " 'année': 50,\n",
       " 'autre': 51,\n",
       " 'naissance': 52,\n",
       " 'article': 53,\n",
       " 'nom': 54,\n",
       " 'après': 55,\n",
       " 'voir': 56,\n",
       " 'commune': 57,\n",
       " 'état': 58,\n",
       " 'ville': 59,\n",
       " 'externe': 60,\n",
       " 'y': 61,\n",
       " 'paris': 62,\n",
       " 'référence': 63,\n",
       " 'entre': 64,\n",
       " 'lui': 65,\n",
       " 'même': 66,\n",
       " 'source': 67,\n",
       " 'sous': 68,\n",
       " 'jean': 69,\n",
       " 'lieu': 70,\n",
       " 'leur': 71,\n",
       " 'site': 72,\n",
       " 'note': 73,\n",
       " 'où': 74,\n",
       " 'dont': 75,\n",
       " 'film': 76,\n",
       " 'ces': 77,\n",
       " 'groupe': 78,\n",
       " 'nouveau': 79,\n",
       " 'depuis': 80,\n",
       " 'décès': 81,\n",
       " 'titre': 82,\n",
       " 'ils': 83,\n",
       " 'date': 84,\n",
       " 'naître': 85,\n",
       " 'national': 86,\n",
       " 'équipe': 87,\n",
       " 'devenir': 88,\n",
       " 'situer': 89,\n",
       " 'devoir': 90,\n",
       " 'ancien': 91,\n",
       " 'partie': 92,\n",
       " 'mettre': 93,\n",
       " 'joueur': 94,\n",
       " 'américain': 95,\n",
       " 'très': 96,\n",
       " 'nord': 97,\n",
       " 'si': 98,\n",
       " 'pays': 99,\n",
       " 'monde': 100,\n",
       " 'page': 101,\n",
       " 'contre': 102,\n",
       " 'prendre': 103,\n",
       " '&': 104,\n",
       " 'fin': 105,\n",
       " 'politique': 106,\n",
       " 'utiliser': 107,\n",
       " 'mort': 108,\n",
       " 'liste': 109,\n",
       " 'dernier': 110,\n",
       " 'dire': 111,\n",
       " 'saison': 112,\n",
       " 'sans': 113,\n",
       " 'série': 114,\n",
       " 'puis': 115,\n",
       " 'janvier': 116,\n",
       " 'trouver': 117,\n",
       " 'région': 118,\n",
       " 'image': 119,\n",
       " 'général': 120,\n",
       " 'plusieurs': 121,\n",
       " 'point': 122,\n",
       " 'pierre': 123,\n",
       " 'permettre': 124,\n",
       " 'certain': 125,\n",
       " 'jour': 126,\n",
       " 'club': 127,\n",
       " 'vers': 128,\n",
       " 'mars': 129,\n",
       " 'histoire': 130,\n",
       " 'mai': 131,\n",
       " 'population': 132,\n",
       " 'créer': 133,\n",
       " 'juin': 134,\n",
       " 'alors': 135,\n",
       " 'donner': 136,\n",
       " 'non': 137,\n",
       " 'homme': 138,\n",
       " 'famille': 139,\n",
       " 'temps': 140,\n",
       " 'place': 141,\n",
       " 'septembre': 142,\n",
       " 'ligne': 143,\n",
       " 'trois': 144,\n",
       " 'bien': 145,\n",
       " 'petit': 146,\n",
       " 'album': 147,\n",
       " 'juillet': 148,\n",
       " 'octobre': 149,\n",
       " 'aller': 150,\n",
       " 'avril': 151,\n",
       " 'membre': 152,\n",
       " 'début': 153,\n",
       " 'jeu': 154,\n",
       " 'connaître': 155,\n",
       " 'août': 156,\n",
       " 'donc': 157,\n",
       " 'décembre': 158,\n",
       " 'guerre': 159,\n",
       " 'novembre': 160,\n",
       " 'département': 161,\n",
       " 'me': 162,\n",
       " 'celle': 163,\n",
       " 'nombreux': 164,\n",
       " 'tour': 165,\n",
       " 'fois': 166,\n",
       " 'février': 167,\n",
       " 'meilleur': 168,\n",
       " 'heure': 169,\n",
       " 'passer': 170,\n",
       " 'principal': 171,\n",
       " 'seul': 172,\n",
       " 'sortir': 173,\n",
       " 'centre': 174,\n",
       " 'cour': 175,\n",
       " 'selon': 176,\n",
       " 'suivant': 177,\n",
       " 'église': 178,\n",
       " \"jusqu'à\": 179,\n",
       " 'siècle': 180,\n",
       " 'ainsi': 181,\n",
       " 'louis': 182,\n",
       " 'vous': 183,\n",
       " 'nombre': 184,\n",
       " 'art': 185,\n",
       " 'football': 186,\n",
       " 'vie': 187,\n",
       " 'village': 188,\n",
       " 'pendant': 189,\n",
       " 'roi': 190,\n",
       " 'leurs': 191,\n",
       " 'connexe': 192,\n",
       " 'sud': 193,\n",
       " 'quelques': 194,\n",
       " 'celui': 195,\n",
       " 'jouer': 196,\n",
       " 'droit': 197,\n",
       " 'allemand': 198,\n",
       " 'espèce': 199,\n",
       " 'international': 200,\n",
       " 'réaliser': 201,\n",
       " 'langue': 202,\n",
       " 'lequel': 203,\n",
       " 'encore': 204,\n",
       " 'musique': 205,\n",
       " 'travail': 206,\n",
       " 'personne': 207,\n",
       " 'édition': 208,\n",
       " 'rester': 209,\n",
       " 'appeler': 210,\n",
       " 'suite': 211,\n",
       " 'historique': 212,\n",
       " 'championnat': 213,\n",
       " 'genre': 214,\n",
       " 'origine': 215,\n",
       " 'écrire': 216,\n",
       " 'femme': 217,\n",
       " 'public': 218,\n",
       " 'eau': 219,\n",
       " 'avant': 220,\n",
       " 'nommer': 221,\n",
       " 'président': 222,\n",
       " 'exemple': 223,\n",
       " 'château': 224,\n",
       " 'important': 225,\n",
       " 'officiel': 226,\n",
       " 'venir': 227,\n",
       " 'fils': 228,\n",
       " 'service': 229,\n",
       " 'rue': 230,\n",
       " 'projet': 231,\n",
       " 'publier': 232,\n",
       " 'porter': 233,\n",
       " 'mondial': 234,\n",
       " 'type': 235,\n",
       " 'but': 236,\n",
       " 'différent': 237,\n",
       " 'second': 238,\n",
       " 'europe': 239,\n",
       " 'épisode': 240,\n",
       " 'acteur': 241,\n",
       " 'chef': 242,\n",
       " 'forme': 243,\n",
       " 'charles': 244,\n",
       " 'or': 245,\n",
       " 'anglais': 246,\n",
       " 'cet': 247,\n",
       " 'auteur': 248,\n",
       " 'long': 249,\n",
       " 'présenter': 250,\n",
       " 'société': 251,\n",
       " 'bon': 252,\n",
       " 'olympique': 253,\n",
       " 'jeune': 254,\n",
       " 'division': 255,\n",
       " 'haut': 256,\n",
       " 'île': 257,\n",
       " 'paul': 258,\n",
       " 'système': 259,\n",
       " 'ordre': 260,\n",
       " 'roman': 261,\n",
       " 'télévision': 262,\n",
       " 'militaire': 263,\n",
       " 'obtenir': 264,\n",
       " 'fonction': 265,\n",
       " 'province': 266,\n",
       " 'prix': 267,\n",
       " 'étude': 268,\n",
       " 'rôle': 269,\n",
       " 'époque': 270,\n",
       " 'bar': 271,\n",
       " 'scène': 272,\n",
       " 'moyen': 273,\n",
       " 'bas': 274,\n",
       " 'texte': 275,\n",
       " 'durant': 276,\n",
       " 'quatre': 277,\n",
       " 'construire': 278,\n",
       " 'sport': 279,\n",
       " 'personnalité': 280,\n",
       " 'saint': 281,\n",
       " 'modèle': 282,\n",
       " 'participer': 283,\n",
       " 'tel': 284,\n",
       " 'rendre': 285,\n",
       " 'père': 286,\n",
       " 'chez': 287,\n",
       " 'carrière': 288,\n",
       " 'enfant': 289,\n",
       " 'deuxième': 290,\n",
       " 'cas': 291,\n",
       " 'final': 292,\n",
       " 'chaque': 293,\n",
       " 'suivre': 294,\n",
       " 'version': 295,\n",
       " 'numéro': 296,\n",
       " 'toujours': 297,\n",
       " 'marie': 298,\n",
       " 'jacques': 299,\n",
       " 'monument': 300,\n",
       " 'françois': 301,\n",
       " 'john': 302,\n",
       " 'ministre': 303,\n",
       " 'base': 304,\n",
       " 'italien': 305,\n",
       " '+': 306,\n",
       " 'habitant': 307,\n",
       " 'comprendre': 308,\n",
       " 'savoir': 309,\n",
       " 'zone': 310,\n",
       " 'activité': 311,\n",
       " 'armée': 312,\n",
       " 'champion': 313,\n",
       " 'production': 314,\n",
       " 'maison': 315,\n",
       " 'falloir': 316,\n",
       " 'recevoir': 317,\n",
       " 'commencer': 318,\n",
       " 'ensemble': 319,\n",
       " 'actuel': 320,\n",
       " 'ouest': 321,\n",
       " 'représenter': 322,\n",
       " 'niveau': 323,\n",
       " 'exister': 324,\n",
       " 'cela': 325,\n",
       " 'école': 326,\n",
       " 'canton': 327,\n",
       " 'période': 328,\n",
       " 'elles': 329,\n",
       " 'remporter': 330,\n",
       " 'mois': 331,\n",
       " 'demander': 332,\n",
       " 'commun': 333,\n",
       " 'gouvernement': 334,\n",
       " 'car': 335,\n",
       " 'agir': 336,\n",
       " 'livre': 337,\n",
       " 'ensuite': 338,\n",
       " 'université': 339,\n",
       " 'composer': 340,\n",
       " 'nous': 341,\n",
       " 'former': 342,\n",
       " 'lier': 343,\n",
       " 'technique': 344,\n",
       " 'ça': 345,\n",
       " 'considérer': 346,\n",
       " 'chanson': 347,\n",
       " 'peu': 348,\n",
       " 'entreprise': 349,\n",
       " 'fille': 350,\n",
       " \"aujourd'hui\": 351,\n",
       " 'européen': 352,\n",
       " 'création': 353,\n",
       " 'robert': 354,\n",
       " 'concerner': 355,\n",
       " 'cependant': 356,\n",
       " 'tard': 357,\n",
       " 'section': 358,\n",
       " 'côté': 359,\n",
       " 'michel': 360,\n",
       " 'argent': 361,\n",
       " 'sembler': 362,\n",
       " 'britannique': 363,\n",
       " 'italie': 364,\n",
       " 'fort': 365,\n",
       " 'souvent': 366,\n",
       " 'personnage': 367,\n",
       " 'moins': 368,\n",
       " 'question': 369,\n",
       " 'vouloir': 370,\n",
       " 'fichier': 371,\n",
       " 'wikipedia': 372,\n",
       " 'victoire': 373,\n",
       " 'fonder': 374,\n",
       " 'recensement': 375,\n",
       " 'force': 376,\n",
       " 'compter': 377,\n",
       " 'style': 378,\n",
       " 'retrouver': 379,\n",
       " 'quand': 380,\n",
       " 'original': 381,\n",
       " 'fait': 382,\n",
       " 'compétition': 383,\n",
       " 'précédent': 384,\n",
       " 'environ': 385,\n",
       " 'recherche': 386,\n",
       " 'siège': 387,\n",
       " 'kilomètre': 388,\n",
       " 'suisse': 389,\n",
       " 'allemagne': 390,\n",
       " 'produire': 391,\n",
       " 'latitude': 392,\n",
       " 'simple': 393,\n",
       " 'déjà': 394,\n",
       " 'route': 395,\n",
       " 'constituer': 396,\n",
       " 'noir': 397,\n",
       " 'problème': 398,\n",
       " 'longitude': 399,\n",
       " 'social': 400,\n",
       " 'construction': 401,\n",
       " 'territoire': 402,\n",
       " 'corps': 403,\n",
       " 'blanc': 404,\n",
       " 'position': 405,\n",
       " 'parti': 406,\n",
       " 'élection': 407,\n",
       " 'troisième': 408,\n",
       " 'reprendre': 409,\n",
       " 'maire': 410,\n",
       " 'proposer': 411,\n",
       " 'loi': 412,\n",
       " 'tête': 413,\n",
       " 'terre': 414,\n",
       " 'résultat': 415,\n",
       " 'vivre': 416,\n",
       " 'ceux': 417,\n",
       " 'tenir': 418,\n",
       " 'là': 419,\n",
       " 'servir': 420,\n",
       " 'terme': 421,\n",
       " 'canada': 422,\n",
       " 'rouge': 423,\n",
       " 'match': 424,\n",
       " 'bataille': 425,\n",
       " 'frère': 426,\n",
       " 'objet': 427,\n",
       " 'parler': 428,\n",
       " 'local': 429,\n",
       " 'dès': 430,\n",
       " 'couleur': 431,\n",
       " 'score': 432,\n",
       " 'soit': 433,\n",
       " 'plan': 434,\n",
       " 'york': 435,\n",
       " 'laisser': 436,\n",
       " 'royal': 437,\n",
       " 'député': 438,\n",
       " 'décider': 439,\n",
       " 'mer': 440,\n",
       " 'développer': 441,\n",
       " 'maître': 442,\n",
       " 'parmi': 443,\n",
       " 'arriver': 444,\n",
       " 'poste': 445,\n",
       " 'direction': 446,\n",
       " 'domaine': 447,\n",
       " 'ouvrir': 448,\n",
       " 'scientifique': 449,\n",
       " 'in': 450,\n",
       " 'arrondissement': 451,\n",
       " 'québec': 452,\n",
       " 'part': 453,\n",
       " 'perdre': 454,\n",
       " 'henri': 455,\n",
       " 'mouvement': 456,\n",
       " 'communauté': 457,\n",
       " 'posséder': 458,\n",
       " 'travailler': 459,\n",
       " 'top': 460,\n",
       " 'action': 461,\n",
       " 'âge': 462,\n",
       " 'pont': 463,\n",
       " 'apparaître': 464,\n",
       " 'supérieur': 465,\n",
       " 'écrivain': 466,\n",
       " 'information': 467,\n",
       " 'espagne': 468,\n",
       " 'science': 469,\n",
       " 'sujet': 470,\n",
       " 'été': 471,\n",
       " 'lancer': 472,\n",
       " 'désigner': 473,\n",
       " 'formation': 474,\n",
       " 'présent': 475,\n",
       " 'penser': 476,\n",
       " 'code': 477,\n",
       " 'libre': 478,\n",
       " 'développement': 479,\n",
       " 'atteindre': 480,\n",
       " 'cinq': 481,\n",
       " 'merci': 482,\n",
       " 'organiser': 483,\n",
       " 'voie': 484,\n",
       " 'pièce': 485,\n",
       " 'réseau': 486,\n",
       " 'quartier': 487,\n",
       " 'classement': 488,\n",
       " 'joseph': 489,\n",
       " 'david': 490,\n",
       " 'culture': 491,\n",
       " 'occuper': 492,\n",
       " 'gare': 493,\n",
       " 'bois': 494,\n",
       " 'discuter': 495,\n",
       " 'compte': 496,\n",
       " 'directeur': 497,\n",
       " 'mourir': 498,\n",
       " 'sortie': 499,\n",
       " 'ici': 500,\n",
       " 'remplacer': 501,\n",
       " 'chemin': 502,\n",
       " 'propre': 503,\n",
       " 'mère': 504,\n",
       " 'affaire': 505,\n",
       " 'mot': 506,\n",
       " 'vainqueur': 507,\n",
       " 'philippe': 508,\n",
       " 'mise': 509,\n",
       " 'beaucoup': 510,\n",
       " 'terminer': 511,\n",
       " 'élire': 512,\n",
       " 'bronze': 513,\n",
       " 'association': 514,\n",
       " 'peintre': 515,\n",
       " 'rejoindre': 516,\n",
       " 'gauche': 517,\n",
       " 'artiste': 518,\n",
       " 'surtout': 519,\n",
       " 'demande': 520,\n",
       " 'carte': 521,\n",
       " 'rencontrer': 522,\n",
       " 'lorsque': 523,\n",
       " 'ouvrage': 524,\n",
       " 'médaille': 525,\n",
       " 'professionnel': 526,\n",
       " 'découvrir': 527,\n",
       " 'marquer': 528,\n",
       " 'claude': 529,\n",
       " 'belge': 530,\n",
       " 'minute': 531,\n",
       " 'divers': 532,\n",
       " 'parfois': 533,\n",
       " 'durée': 534,\n",
       " 'retour': 535,\n",
       " 'classer': 536,\n",
       " 'musée': 537,\n",
       " 'installer': 538,\n",
       " 'milieu': 539,\n",
       " 'devant': 540,\n",
       " 'beau': 541,\n",
       " 'possible': 542,\n",
       " 'municipalité': 543,\n",
       " 'sélection': 544,\n",
       " 'lettre': 545,\n",
       " 'bâtiment': 546,\n",
       " 'prince': 547,\n",
       " 'succès': 548,\n",
       " 'superficie': 549,\n",
       " 'georges': 550,\n",
       " 'montrer': 551,\n",
       " 'théâtre': 552,\n",
       " 'mon': 553,\n",
       " 'diriger': 554,\n",
       " 'jamais': 555,\n",
       " 'central': 556,\n",
       " 'conseil': 557,\n",
       " 'double': 558,\n",
       " 'sou': 559,\n",
       " 'naturel': 560,\n",
       " 'afrique': 561,\n",
       " 'russe': 562,\n",
       " 'court': 563,\n",
       " 'martin': 564,\n",
       " 'élément': 565,\n",
       " 'cinéma': 566,\n",
       " 'espagnol': 567,\n",
       " 'espace': 568,\n",
       " 'van': 569,\n",
       " 'belgique': 570,\n",
       " 'san': 571,\n",
       " 'établir': 572,\n",
       " 'musical': 573,\n",
       " 'bande': 574,\n",
       " 'autres': 575,\n",
       " 'contenir': 576,\n",
       " 'sein': 577,\n",
       " 'parcours': 578,\n",
       " 'angleterre': 579,\n",
       " 'élever': 580,\n",
       " 'andré': 581,\n",
       " 'parc': 582,\n",
       " 'japonais': 583,\n",
       " 'voix': 584,\n",
       " 'étranger': 585,\n",
       " 'agglomération': 586,\n",
       " 'combat': 587,\n",
       " 'total': 588,\n",
       " 'aide': 589,\n",
       " 'rome': 590,\n",
       " 'effectuer': 591,\n",
       " 'valeur': 592,\n",
       " 'conserver': 593,\n",
       " 'critique': 594,\n",
       " 'duc': 595,\n",
       " 'sens': 596,\n",
       " 'discussion': 597,\n",
       " 'fer': 598,\n",
       " 'trop': 599,\n",
       " 'moment': 600,\n",
       " 'hockey': 601,\n",
       " 'eux': 602,\n",
       " 'mener': 603,\n",
       " 'jpg': 604,\n",
       " 'district': 605,\n",
       " 'inscrire': 606,\n",
       " 'amérique': 607,\n",
       " 'professeur': 608,\n",
       " 'ajouter': 609,\n",
       " 'comte': 610,\n",
       " 'coupe': 611,\n",
       " 'compagnie': 612,\n",
       " 'économique': 613,\n",
       " 'quitter': 614,\n",
       " 'idée': 615,\n",
       " 'administration': 616,\n",
       " 'japon': 617,\n",
       " 'port': 618,\n",
       " 'tableau': 619,\n",
       " 'honneur': 620,\n",
       " 'ni': 621,\n",
       " 'proche': 622,\n",
       " 'adresser': 623,\n",
       " 'million': 624,\n",
       " 'romain': 625,\n",
       " 'rapport': 626,\n",
       " 'revenir': 627,\n",
       " 'aucun': 628,\n",
       " 'religieux': 629,\n",
       " 'comté': 630,\n",
       " 'produit': 631,\n",
       " 'paraître': 632,\n",
       " 'chanteur': 633,\n",
       " 'relation': 634,\n",
       " 'conseiller': 635,\n",
       " 'main': 636,\n",
       " 'entraîneur': 637,\n",
       " 'organisation': 638,\n",
       " 'transport': 639,\n",
       " 'croix': 640,\n",
       " 'cadre': 641,\n",
       " 'station': 642,\n",
       " 'émission': 643,\n",
       " 'ami': 644,\n",
       " 'publication': 645,\n",
       " 'unité': 646,\n",
       " 'taille': 647,\n",
       " 'enfin': 648,\n",
       " 'étape': 649,\n",
       " 'vue': 650,\n",
       " 'communal': 651,\n",
       " 'réalisateur': 652,\n",
       " 'glace': 653,\n",
       " 'manière': 654,\n",
       " 'moi': 655,\n",
       " 'rien': 656,\n",
       " 'appartenir': 657,\n",
       " 'assurer': 658,\n",
       " 'sportif': 659,\n",
       " 'indiquer': 660,\n",
       " 'droite': 661,\n",
       " 'partir': 662,\n",
       " 'six': 663,\n",
       " 'classe': 664,\n",
       " 'régional': 665,\n",
       " 'personnel': 666,\n",
       " 'raison': 667,\n",
       " 'arme': 668,\n",
       " \"jusqu'en\": 669,\n",
       " 'canadien': 670,\n",
       " 'londres': 671,\n",
       " 'assez': 672,\n",
       " 'signer': 673,\n",
       " 'mètre': 674,\n",
       " 'malgré': 675,\n",
       " 'intérieur': 676,\n",
       " 'évêque': 677,\n",
       " 'tuer': 678,\n",
       " 'charger': 679,\n",
       " 'placer': 680,\n",
       " 'tourner': 681,\n",
       " 'entrer': 682,\n",
       " 'course': 683,\n",
       " 'fiche': 684,\n",
       " 'collection': 685,\n",
       " 'salle': 686,\n",
       " 'journal': 687,\n",
       " 'également': 688,\n",
       " 'continuer': 689,\n",
       " 'coup': 690,\n",
       " 'programme': 691,\n",
       " 'porte': 692,\n",
       " 'étudiant': 693,\n",
       " 'diffusion': 694,\n",
       " 'mission': 695,\n",
       " 'populaire': 696,\n",
       " 'passage': 697,\n",
       " 'rivière': 698,\n",
       " 'ball': 699,\n",
       " 'dérouler': 700,\n",
       " 'consacrer': 701,\n",
       " 'richard': 702,\n",
       " 'james': 703,\n",
       " 'semaine': 704,\n",
       " 'dix': 705,\n",
       " 'civil': 706,\n",
       " 'campagne': 707,\n",
       " '°': 708,\n",
       " 'mesure': 709,\n",
       " 'demi': 710,\n",
       " 'choisir': 711,\n",
       " 'web': 712,\n",
       " 'évolution': 713,\n",
       " 'envoyer': 714,\n",
       " 'plupart': 715,\n",
       " 'william': 716,\n",
       " 'féminin': 717,\n",
       " 'lire': 718,\n",
       " 'évoluer': 719,\n",
       " 'effet': 720,\n",
       " 'annoncer': 721,\n",
       " 'humain': 722,\n",
       " 'compositeur': 723,\n",
       " 'priver': 724,\n",
       " 'stade': 725,\n",
       " 'thomas': 726,\n",
       " 'urbain': 727,\n",
       " 'troupe': 728,\n",
       " 'reconnaître': 729,\n",
       " 'classique': 730,\n",
       " 'vitesse': 731,\n",
       " 'russie': 732,\n",
       " 'loire': 733,\n",
       " 'façon': 734,\n",
       " 'diffuser': 735,\n",
       " 'george': 736,\n",
       " 'gagner': 737,\n",
       " 'situation': 738,\n",
       " 'ma': 739,\n",
       " 'téléviser': 740,\n",
       " 'single': 741,\n",
       " 'disposer': 742,\n",
       " 'dater': 743,\n",
       " 'catholique': 744,\n",
       " 'subdivision': 745,\n",
       " 'grec': 746,\n",
       " 'royaume': 747,\n",
       " 'producteur': 748,\n",
       " 'abord': 749,\n",
       " 'bretagne': 750,\n",
       " 'dessus': 751,\n",
       " 'décision': 752,\n",
       " 'navire': 753,\n",
       " 'célèbre': 754,\n",
       " 'issir': 755,\n",
       " 'qualité': 756,\n",
       " 'michael': 757,\n",
       " 'tenter': 758,\n",
       " 'majeur': 759,\n",
       " 'engager': 760,\n",
       " 'nicolas': 761,\n",
       " 'vol': 762,\n",
       " 'battre': 763,\n",
       " 'lac': 764,\n",
       " 'actif': 765,\n",
       " 'entrée': 766,\n",
       " 'footballeur': 767,\n",
       " 'inconnu': 768,\n",
       " 'utilisation': 769,\n",
       " 'air': 770,\n",
       " 'bernard': 771,\n",
       " 'nature': 772,\n",
       " 'présence': 773,\n",
       " 'docteur': 774,\n",
       " 'chose': 775,\n",
       " 'moteur': 776,\n",
       " 'opération': 777,\n",
       " 'ailleurs': 778,\n",
       " 'régiment': 779,\n",
       " 'réalisation': 780,\n",
       " 'toutefois': 781,\n",
       " 'arrêter': 782,\n",
       " 'chine': 783,\n",
       " 'hiver': 784,\n",
       " 'offrir': 785,\n",
       " 'chaîne': 786,\n",
       " 'culturel': 787,\n",
       " 'mal': 788,\n",
       " 'mode': 789,\n",
       " 'photo': 790,\n",
       " 'scénario': 791,\n",
       " 'moderne': 792,\n",
       " 'changer': 793,\n",
       " 'occasion': 794,\n",
       " 'officier': 795,\n",
       " 'chercher': 796,\n",
       " 'mont': 797,\n",
       " 'enregistrer': 798,\n",
       " 'lyon': 799,\n",
       " 'toute': 800,\n",
       " 'portail': 801,\n",
       " 'attaque': 802,\n",
       " 'dessiner': 803,\n",
       " 'condition': 804,\n",
       " 'statut': 805,\n",
       " 'intérêt': 806,\n",
       " 'poser': 807,\n",
       " 'particulier': 808,\n",
       " 'principe': 809,\n",
       " 'finir': 810,\n",
       " 'déclarer': 811,\n",
       " 'terrain': 812,\n",
       " 'expliquer': 813,\n",
       " 'montagne': 814,\n",
       " 'animal': 815,\n",
       " \"lorsqu'\": 816,\n",
       " 'chapelle': 817,\n",
       " 'localité': 818,\n",
       " 'protéger': 819,\n",
       " 'peuple': 820,\n",
       " 'donnée': 821,\n",
       " 'structure': 822,\n",
       " 'presse': 823,\n",
       " 'latin': 824,\n",
       " 'intituler': 825,\n",
       " 'citer': 826,\n",
       " 'baser': 827,\n",
       " 'chacun': 828,\n",
       " 'utilisateur': 829,\n",
       " 'tomber': 830,\n",
       " 'opposer': 831,\n",
       " 'vieux': 832,\n",
       " 'associer': 833,\n",
       " 'amour': 834,\n",
       " 'pied': 835,\n",
       " 'décrire': 836,\n",
       " 'vendre': 837,\n",
       " 'chinois': 838,\n",
       " 'valoir': 839,\n",
       " 'élève': 840,\n",
       " 'aucune': 841,\n",
       " 'australie': 842,\n",
       " 'montréal': 843,\n",
       " 'sept': 844,\n",
       " 'courant': 845,\n",
       " 'départ': 846,\n",
       " 'caractère': 847,\n",
       " 'tirer': 848,\n",
       " 'étudier': 849,\n",
       " 'marc': 850,\n",
       " 'interne': 851,\n",
       " 'anne': 852,\n",
       " 'conflit': 853,\n",
       " 'éditeur': 854,\n",
       " 'vert': 855,\n",
       " 'rugby': 856,\n",
       " 'intégrer': 857,\n",
       " 'traduction': 858,\n",
       " 'nuit': 859,\n",
       " 'mandat': 860,\n",
       " 'capitale': 861,\n",
       " 'large': 862,\n",
       " 'répondre': 863,\n",
       " 'usage': 864,\n",
       " 'règle': 865,\n",
       " 'vidéo': 866,\n",
       " 'mieux': 867,\n",
       " 'exposition': 868,\n",
       " 'marine': 869,\n",
       " 'charge': 870,\n",
       " 'avis': 871,\n",
       " 'administratif': 872,\n",
       " 'détruire': 873,\n",
       " 'maurice': 874,\n",
       " 'croire': 875,\n",
       " 'empereur': 876,\n",
       " 'volume': 877,\n",
       " 'format': 878,\n",
       " 'tournoi': 879,\n",
       " 'surface': 880,\n",
       " 'seine': 881,\n",
       " 'municipal': 882,\n",
       " 'marché': 883,\n",
       " 'supprimer': 884,\n",
       " 'pratique': 885,\n",
       " 'influence': 886,\n",
       " 'altitude': 887,\n",
       " 'imposer': 888,\n",
       " 'soutenir': 889,\n",
       " 'logo': 890,\n",
       " 'antoine': 891,\n",
       " 'accepter': 892,\n",
       " 'qualifier': 893,\n",
       " 'label': 894,\n",
       " 'abbaye': 895,\n",
       " 'propriétaire': 896,\n",
       " 'avion': 897,\n",
       " 'étendre': 898,\n",
       " 'débuter': 899,\n",
       " 'forêt': 900,\n",
       " 'prévoir': 901,\n",
       " 'littérature': 902,\n",
       " 'épreuve': 903,\n",
       " 'journaliste': 904,\n",
       " 'vallée': 905,\n",
       " 'refuser': 906,\n",
       " 'disparaître': 907,\n",
       " 'secteur': 908,\n",
       " 'modifier': 909,\n",
       " 'chrétien': 910,\n",
       " 'for': 911,\n",
       " 'contrôle': 912,\n",
       " 'unique': 913,\n",
       " 'juste': 914,\n",
       " 'bruxelles': 915,\n",
       " 'seigneur': 916,\n",
       " 'définir': 917,\n",
       " 'accueillir': 918,\n",
       " 'table': 919,\n",
       " 'décéder': 920,\n",
       " 'conduire': 921,\n",
       " 'regrouper': 922,\n",
       " 'complet': 923,\n",
       " 'choix': 924,\n",
       " 'théorie': 925,\n",
       " 'parvenir': 926,\n",
       " 'autorité': 927,\n",
       " 'acte': 928,\n",
       " 'côte': 929,\n",
       " 'record': 930,\n",
       " 'rencontre': 931,\n",
       " 'revue': 932,\n",
       " 'taire': 933,\n",
       " 'guillaume': 934,\n",
       " 'daniel': 935,\n",
       " 'traverser': 936,\n",
       " 'patrimoine': 937,\n",
       " 'file': 938,\n",
       " 'border': 939,\n",
       " 'automobile': 940,\n",
       " 'architecture': 941,\n",
       " 'réponse': 942,\n",
       " 'comporter': 943,\n",
       " 'feu': 944,\n",
       " 'albert': 945,\n",
       " 'quel': 946,\n",
       " 'accompagner': 947,\n",
       " 'traduire': 948,\n",
       " 'méthode': 949,\n",
       " 'limiter': 950,\n",
       " 'épouser': 951,\n",
       " 'peter': 952,\n",
       " 'architecte': 953,\n",
       " 'aimer': 954,\n",
       " 'futur': 955,\n",
       " 'physique': 956,\n",
       " 'noter': 957,\n",
       " 'phase': 958,\n",
       " 'poursuivre': 959,\n",
       " 'essai': 960,\n",
       " 'commercial': 961,\n",
       " 'disputer': 962,\n",
       " 'besoin': 963,\n",
       " 'destiner': 964,\n",
       " 'pologne': 965,\n",
       " 'propriété': 966,\n",
       " 'radio': 967,\n",
       " 'extérieur': 968,\n",
       " 'aider': 969,\n",
       " 'nécessaire': 970,\n",
       " 'bleu': 971,\n",
       " 'alexandre': 972,\n",
       " 'piste': 973,\n",
       " 'train': 974,\n",
       " 'industriel': 975,\n",
       " 'frontière': 976,\n",
       " 'votre': 977,\n",
       " 'attendre': 978,\n",
       " 'inclure': 979,\n",
       " 'majorité': 980,\n",
       " 'contributeur': 981,\n",
       " 'photographie': 982,\n",
       " 'cheval': 983,\n",
       " 'sécurité': 984,\n",
       " 'taux': 985,\n",
       " 'fondateur': 986,\n",
       " 'longueur': 987,\n",
       " 'message': 988,\n",
       " 'peinture': 989,\n",
       " 'alpes': 990,\n",
       " 'énergie': 991,\n",
       " 'inspirer': 992,\n",
       " 'dessin': 993,\n",
       " 'relier': 994,\n",
       " 'marier': 995,\n",
       " 'voyage': 996,\n",
       " 'fédéral': 997,\n",
       " 'hôtel': 998,\n",
       " 'face': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.67579126e-01, -9.34297621e-01, -3.89060646e-01, -2.03962207e-01,\n",
       "        6.24373436e-01,  5.58501959e-01, -7.94236243e-01,  9.47133780e-01,\n",
       "       -7.85477459e-01, -4.23343748e-01, -3.78552794e-01,  9.85341787e-01,\n",
       "       -9.94831264e-01,  7.94630885e-01, -3.72711942e-02, -1.31745422e+00,\n",
       "       -2.15552300e-01, -1.77847058e-01,  4.44615424e-01,  2.40859807e-01,\n",
       "       -1.34950832e-01,  2.62641966e-01,  7.27709755e-02, -4.39429581e-01,\n",
       "        3.13311636e-01,  4.89237309e-01, -3.47837150e-01,  6.98559701e-01,\n",
       "        3.06835920e-01,  8.79080057e-01, -5.81417084e-01, -3.37294281e-01,\n",
       "        1.81973651e-01,  7.02408612e-01,  7.81347573e-01,  5.16828001e-01,\n",
       "        2.21238777e-01, -4.01979834e-01, -3.04546077e-02,  5.94205201e-01,\n",
       "        7.80208051e-01, -4.02492434e-01,  1.09107220e+00,  1.95819825e-01,\n",
       "        1.20070234e-01,  4.59087253e-01,  6.24428272e-01,  3.55202556e-02,\n",
       "       -1.29575109e+00, -5.80421746e-01,  4.97552425e-01,  3.83994550e-01,\n",
       "       -6.25843883e-01,  4.02111821e-02, -1.67116463e-01, -2.88708836e-01,\n",
       "        2.37573251e-01,  1.95986062e-01, -1.05311256e-02, -6.41048551e-01,\n",
       "        5.71056068e-01, -1.67602494e-01, -3.34718488e-02, -9.81091321e-01,\n",
       "        9.53814201e-03, -8.11713278e-01,  7.95476809e-02,  1.35371459e+00,\n",
       "       -8.95129681e-01, -6.32692948e-02,  7.99319267e-01,  3.66717964e-01,\n",
       "       -1.59692094e-01, -9.30038542e-02, -7.31883496e-02, -8.99896801e-01,\n",
       "        9.05023575e-01, -8.91568482e-01,  2.78179556e-01,  5.08063018e-01,\n",
       "       -4.87549573e-01, -7.06173182e-02,  2.58887976e-01,  6.59917235e-01,\n",
       "        7.12732852e-01,  2.11119547e-01,  1.06469989e+00,  3.81493896e-01,\n",
       "        8.52561831e-01, -1.25596538e-01,  7.37695336e-01,  1.05388904e+00,\n",
       "       -3.90309274e-01, -6.73814714e-01, -3.22097450e-01,  1.13174808e+00,\n",
       "        1.62611723e-01, -2.69456178e-01,  1.85659736e-01, -5.40597178e-02,\n",
       "       -2.08331943e-02, -7.42007315e-01, -2.03088094e-02, -8.08959082e-02,\n",
       "       -2.97963679e-01,  9.37243462e-01, -6.98821425e-01, -3.12172294e-01,\n",
       "        6.16663462e-03,  2.14802831e-01,  6.28498077e-01, -9.41938519e-01,\n",
       "        9.80877429e-02, -2.46762589e-01,  3.31673265e-01, -1.58901423e-01,\n",
       "        1.40867159e-01, -7.18659997e-01,  5.35167277e-01, -1.10918857e-01,\n",
       "       -2.74843991e-01,  8.27234685e-01, -1.51237264e-01,  4.97366637e-01,\n",
       "        7.35036850e-01,  6.56639695e-01,  4.41567242e-01, -5.11551559e-01,\n",
       "        1.04994960e-01,  7.30623305e-01, -4.50633526e-01,  6.61458254e-01,\n",
       "       -5.93046188e-01,  2.41722658e-01,  8.76187563e-01,  3.88294905e-01,\n",
       "        6.64325714e-01, -7.12698519e-01, -1.83607936e-01, -5.77760696e-01,\n",
       "       -5.73671877e-01,  5.43716490e-01, -1.47844329e-01, -1.22091193e-02,\n",
       "       -1.34855762e-01, -2.37819672e-01, -1.13458276e-01, -5.23913428e-02,\n",
       "       -7.00669885e-01, -7.67908767e-02, -1.91256255e-01, -8.10128272e-01,\n",
       "       -2.92287134e-02, -1.21613517e-01,  1.65298209e-01, -2.89676845e-01,\n",
       "        3.57025266e-02,  4.44399416e-01,  1.64545804e-01, -3.51870030e-01,\n",
       "       -7.55682707e-01,  4.48098481e-01,  2.72804424e-02, -2.49902382e-01,\n",
       "        1.12146199e+00, -1.45386815e-01,  6.30960405e-01, -5.99887967e-01,\n",
       "        1.09649563e+00, -6.12319112e-01, -5.11873141e-02, -3.43209893e-01,\n",
       "       -2.45456770e-01,  4.50746179e-01, -3.29754025e-01,  4.05639917e-01,\n",
       "        2.33088106e-01, -9.39936221e-01,  9.31461513e-01,  1.05931687e+00,\n",
       "       -1.02699792e+00, -2.33360335e-01, -3.63129899e-02,  1.40277132e-01,\n",
       "        5.53545117e-01, -3.22930664e-01,  2.47732162e-01, -6.81092501e-01,\n",
       "       -1.90183356e-01, -1.13856447e+00, -5.96219718e-01, -6.78175271e-01,\n",
       "       -3.16019237e-01,  3.26801419e-01, -2.93449789e-01, -4.90465641e-01,\n",
       "       -4.54375893e-01,  1.63799450e-01,  5.17210186e-01, -1.82543918e-02,\n",
       "        5.08228302e-01, -2.23036140e-01, -3.27915668e-01, -1.12596139e-01,\n",
       "       -5.89109778e-01,  1.00309932e+00,  1.23088621e-01,  3.02748978e-01,\n",
       "       -1.00855696e+00,  8.74054790e-01, -1.45482510e-01, -6.95406571e-02,\n",
       "       -2.22767770e-01, -2.46926412e-01, -7.31470108e-01, -5.90223446e-02,\n",
       "        1.37925357e-01, -3.38435918e-01, -8.13203827e-02,  2.22654402e-01,\n",
       "       -3.59112412e-01, -4.86246973e-01, -2.71593273e-01, -1.68677539e-01,\n",
       "        9.87279788e-02, -8.42608929e-01, -5.51463604e-01, -7.37692639e-02,\n",
       "        1.05621912e-01,  5.42728603e-01, -4.32479590e-01, -6.66136980e-01,\n",
       "        3.04283410e-01, -1.44665790e+00, -4.93464798e-01,  6.60050437e-02,\n",
       "       -6.36300147e-01, -5.89841604e-01, -2.21923962e-01,  3.30378324e-01,\n",
       "        2.97987729e-01,  2.14909211e-01,  2.70997196e-01, -2.68213928e-01,\n",
       "        1.37521297e-01, -1.72085226e-01, -1.26124227e+00,  4.38032538e-01,\n",
       "        1.83513314e-02, -7.63768256e-01,  7.70925343e-01, -2.01356038e-01,\n",
       "       -1.06347583e-01, -1.23964763e+00, -8.70603502e-01, -1.04876608e-01,\n",
       "        5.78616023e-01, -1.91954315e-01, -3.74987662e-01, -3.02528143e-01,\n",
       "       -7.27939978e-02, -4.82454956e-01, -3.43767889e-02, -4.48648304e-01,\n",
       "       -9.93474424e-02,  6.44384861e-01, -3.59343380e-01, -1.34250021e+00,\n",
       "        2.74756223e-01,  2.02153996e-02,  5.22282235e-02,  7.21830368e-01,\n",
       "        1.62729189e-01, -1.20380771e+00,  7.93352664e-01, -1.47643602e+00,\n",
       "        2.60039359e-01, -2.72429511e-02, -2.26239473e-01,  5.02546191e-01,\n",
       "       -2.13537738e-01,  3.02719533e-01,  2.99583554e-01,  9.12267923e-01,\n",
       "        1.15872324e+00, -6.06051028e-01, -5.80579877e-01, -2.40231395e-01,\n",
       "        7.34889030e-01,  5.20455897e-01,  2.56906271e-01,  9.66665626e-01,\n",
       "        2.98938453e-01,  2.59995162e-01,  4.62431833e-03, -1.08904272e-01,\n",
       "        1.04511940e+00, -1.07057638e-01, -1.02830017e+00,  6.30850270e-02,\n",
       "        1.58311307e+00,  3.59315813e-01, -4.71951365e-01,  1.32352507e+00,\n",
       "        2.09773153e-01,  8.45640600e-01,  6.77022219e-01, -1.52733445e-01,\n",
       "        4.56769794e-01, -2.19301775e-01,  3.03816527e-01, -3.89337152e-01,\n",
       "        5.06950915e-01,  2.63409793e-01, -8.22743058e-01,  6.38298690e-02,\n",
       "       -3.71655941e-01, -4.12124813e-01,  2.72206694e-01, -5.20301014e-02,\n",
       "        3.10400426e-01,  8.82076263e-01, -7.53150284e-01,  9.49649036e-01,\n",
       "       -3.41179222e-01, -4.65658307e-01,  5.50637662e-01, -2.72470087e-01,\n",
       "        6.16510689e-01,  1.38573372e+00, -1.34571880e-01,  2.07237929e-01,\n",
       "       -3.39499623e-01, -6.53636873e-01, -1.21634588e-01,  1.05775990e-01,\n",
       "       -5.99089324e-01, -8.67248654e-01, -2.47545704e-01, -3.28183502e-01,\n",
       "        1.30094349e+00,  4.23033327e-01,  4.36685652e-01,  8.97645950e-02,\n",
       "       -3.96147728e-01, -4.32819724e-01, -1.42626166e-01, -6.63222149e-02,\n",
       "        7.03744054e-01, -3.56200099e-01, -2.50360996e-01,  1.20342217e-01,\n",
       "       -7.39836693e-02, -9.51059282e-01,  9.56406817e-02,  6.92482114e-01,\n",
       "        1.19735800e-01, -6.33462548e-01, -5.51384747e-01, -1.45102069e-01,\n",
       "        2.01672047e-01, -7.04401493e-01,  2.46975318e-01,  4.87902492e-01,\n",
       "       -6.36297584e-01, -2.54795343e-01, -5.73987722e-01,  3.34528327e-01,\n",
       "       -1.63797708e-03, -1.12062506e-01,  5.04024699e-02,  1.06820025e-01,\n",
       "        5.35830915e-01,  7.09905863e-01,  1.64342260e+00,  6.94562346e-02,\n",
       "       -2.76692182e-01,  8.84908855e-01,  1.20320606e+00, -2.91427344e-01,\n",
       "       -2.08447054e-01, -1.75825298e-01, -5.41926801e-01, -2.54910529e-01,\n",
       "        1.36090472e-01, -2.96047062e-01,  3.70568693e-01, -2.89062381e-01,\n",
       "       -1.48653209e-01, -8.27324390e-01, -6.66954041e-01, -1.34472579e-01,\n",
       "       -6.47119939e-01,  1.66483223e-01, -2.45238528e-01, -1.14619359e-01,\n",
       "        5.42688906e-01,  3.99921574e-02,  1.04906596e-01, -1.13718963e+00,\n",
       "        1.46515012e+00, -1.02616632e-02, -8.98968816e-01,  3.69607270e-01,\n",
       "       -2.29681760e-01, -2.49774262e-01, -7.40407407e-01, -1.11350574e-01,\n",
       "       -2.33427659e-01, -1.08439839e+00, -8.86289358e-01,  4.13769484e-01,\n",
       "        6.68701380e-02, -3.42955589e-01, -1.11296427e+00,  8.60800445e-02,\n",
       "        2.51265377e-01,  8.89613807e-01, -3.00713390e-01,  3.98848891e-01,\n",
       "        3.27407032e-01,  1.57406107e-01,  1.29897863e-01, -3.29155147e-01,\n",
       "       -9.74087119e-02, -6.53313935e-01,  4.83497590e-01, -3.06647003e-01,\n",
       "        1.04956198e+00, -4.91446890e-02,  8.65048409e-01,  3.38934302e-01,\n",
       "       -5.52663684e-01, -4.56480503e-01, -8.61003716e-03,  1.70475650e+00,\n",
       "        1.08259916e+00, -3.86413157e-01, -1.32156983e-01, -2.48404637e-01,\n",
       "        1.29802442e+00,  9.90799546e-01,  7.71072626e-01, -1.57636657e-01,\n",
       "       -2.19004661e-01,  5.64930141e-01, -3.34365934e-01,  6.75777495e-01,\n",
       "       -2.90759444e-01, -1.52834192e-01,  9.02679741e-01, -2.75694162e-01,\n",
       "       -2.09139481e-01,  6.42995417e-01, -9.64815021e-01, -4.87045586e-01,\n",
       "       -1.03398490e+00, -1.36379242e-01, -1.78809971e-01,  3.07844970e-02,\n",
       "       -1.96363986e-01,  5.68758249e-01,  1.36747271e-01, -7.45493174e-01,\n",
       "       -3.60989094e-01,  6.21636510e-01,  5.64389765e-01,  2.93397508e-03,\n",
       "       -8.33906829e-01, -5.59516907e-01,  1.58298641e-01, -4.19919819e-01,\n",
       "       -3.66355807e-01,  1.73880979e-02,  7.74477780e-01, -4.36251223e-01,\n",
       "       -6.20552674e-02,  3.86596531e-01,  3.61152023e-01,  8.29887018e-02,\n",
       "       -3.16545367e-01,  1.44356146e-01, -7.01956868e-01, -5.34214020e-01,\n",
       "       -1.85741514e-01, -1.47341505e-01,  5.13362646e-01, -9.95531142e-01,\n",
       "       -9.95757356e-02,  4.11335304e-02, -5.01943886e-01, -5.09249978e-02,\n",
       "        1.12075865e-01, -1.99480191e-01,  3.03745598e-01,  9.92574692e-01,\n",
       "        1.76622257e-01, -2.74035245e-01, -9.75075811e-02, -6.84415936e-01,\n",
       "       -2.04500094e-01, -4.91435707e-01, -5.38160384e-01,  1.44297004e-01,\n",
       "        3.68504137e-01, -1.02614798e-01,  2.59266049e-01,  4.13876384e-01,\n",
       "        8.67570400e-01, -4.82995600e-01, -3.10304850e-01,  2.37433001e-01,\n",
       "       -9.43157315e-01,  5.03282368e-01,  8.13757896e-01,  5.44713557e-01,\n",
       "        1.64193749e-01, -2.88244486e-01, -4.33488607e-01,  5.07646680e-01,\n",
       "        2.94854254e-01, -2.18047857e-01, -2.96092749e-01, -7.50092924e-01,\n",
       "        2.03256935e-01,  1.17120303e-01,  1.43355966e-01,  4.68491971e-01,\n",
       "       -7.65553236e-01,  1.64541543e-01, -3.86521399e-01,  3.02814096e-01,\n",
       "       -7.97197998e-01, -1.34046748e-01,  3.61504555e-01,  7.47369409e-01,\n",
       "        6.83685005e-01, -6.07452750e-01, -8.61072987e-02, -6.81065675e-03,\n",
       "        5.18270470e-02, -1.09340802e-01, -8.79147708e-01,  2.26266280e-01,\n",
       "        2.96096057e-01, -5.39935768e-01, -3.18014443e-01, -1.23137549e-01,\n",
       "       -2.32704580e-02,  3.71988088e-01, -9.52015296e-02, -7.64613450e-01,\n",
       "        6.13726139e-01, -5.87443590e-01, -1.09354210e+00, -2.70567775e-01,\n",
       "       -3.87310952e-01,  1.02052368e-01,  4.42323476e-01,  2.81536281e-02,\n",
       "       -5.91531634e-01, -2.82258302e-01, -2.47518849e-02,  1.17920303e+00,\n",
       "        5.71500599e-01, -1.73248768e-01, -4.31610376e-01, -7.56663904e-02,\n",
       "       -4.14820224e-01,  3.45567077e-01, -3.97107936e-02,  7.48610497e-02,\n",
       "       -1.31437778e-01, -4.62265104e-01,  2.88244009e-01, -1.51228175e-01,\n",
       "        8.03435087e-01, -1.25295654e-01,  1.32311553e-01, -4.07700092e-01,\n",
       "       -2.33267117e-02,  7.05864966e-01, -6.05441630e-01,  3.39937836e-01,\n",
       "        1.45732284e-01,  7.25149512e-02, -1.98078141e-01, -8.02953064e-01,\n",
       "       -1.29950726e-02, -5.47135949e-01,  5.94918132e-01, -2.23544776e-01,\n",
       "        4.13303256e-01,  4.71579820e-01,  6.69899106e-01,  5.97547650e-01,\n",
       "        2.05604345e-01, -6.64332867e-01,  3.80126238e-01, -6.18129130e-03,\n",
       "        2.90732712e-01, -1.20666623e-01, -9.72738922e-01,  1.39240324e-01,\n",
       "        2.36141294e-01, -6.26896977e-01,  1.70403540e-01,  1.73117667e-01,\n",
       "        1.12495683e-01,  8.32356066e-02, -3.34135741e-01,  3.80744636e-01,\n",
       "       -2.59999424e-01,  1.29647923e+00,  3.40001643e-01,  2.19689339e-01,\n",
       "        8.82253230e-01,  1.12707846e-01, -6.36712015e-01, -4.17713702e-01,\n",
       "        6.07774258e-01, -5.27768970e-01, -7.08885550e-01, -7.24545836e-01,\n",
       "        4.63197738e-01, -6.76877379e-01, -5.44933736e-01, -1.99850738e-01,\n",
       "        8.97430778e-01,  4.92413826e-02,  1.50183171e-01,  4.69598800e-01,\n",
       "        2.07603216e-01, -4.73009825e-01, -1.00822163e+00, -4.40766215e-02,\n",
       "        1.51380628e-01, -2.17882261e-01, -2.23561630e-01,  7.55998313e-01,\n",
       "        4.36851263e-01, -3.33539546e-01, -3.90896797e-02,  3.17714691e-01,\n",
       "       -3.78571332e-01, -3.67802143e-01, -7.00299442e-02, -7.48388246e-02,\n",
       "       -1.41743168e-01, -1.72362328e-01, -3.07423353e-01,  2.98040897e-01,\n",
       "        2.46473968e-01,  1.32397830e-01,  1.04720104e+00,  3.58292073e-01,\n",
       "        1.03869125e-01,  4.75986421e-01, -2.60389745e-01, -7.86486268e-03,\n",
       "        5.99572897e-01,  3.60617757e-01, -1.08815260e-01, -1.22736394e+00,\n",
       "        3.81040543e-01,  2.20555037e-01,  5.87766647e-01, -6.71569169e-01,\n",
       "        1.45082867e+00, -7.78131112e-02, -9.48488772e-01,  3.48283857e-01,\n",
       "        4.90349412e-01,  4.14216518e-01,  6.45747900e-01, -3.07553083e-01,\n",
       "       -3.29392821e-01, -3.31324875e-01, -1.35984376e-01,  3.71608406e-01,\n",
       "        8.51248264e-01, -4.11335558e-01, -4.83015895e-01, -2.07950592e-01,\n",
       "        1.49750531e-01,  3.68860960e-01,  4.75695163e-01, -1.17586267e+00,\n",
       "        2.81834565e-02,  5.72014488e-02,  3.51272225e-01, -2.51247615e-01,\n",
       "        7.99956679e-01, -1.93470642e-01, -3.30183208e-01, -6.98590934e-01,\n",
       "        3.42658848e-01, -5.70239663e-01,  3.12321689e-02,  3.46526802e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"bonjour\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le plongement pré-entrainé est de dimension 700."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model[\"bonjour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(embeddings_model):\n",
    "    embeddings_index = {}\n",
    "    for word in list(embeddings_model.key_to_index.keys()):\n",
    "        embeddings_index[word] = embeddings_model[word]\n",
    "    print(f'{len(embeddings_index)} vecteurs de mots ont été lus')\n",
    "    return embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = load_embeddings(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La cellule suivante permet de créer une matrice de plongements: une matrice où la ligne i correspond au plongement pré-entraîné pour le mot d'indice i dans le vocabulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_matrix(vocabulary, embeddings_index, embedding_dim = 700):\n",
    "  num_tokens = len(vocabulary)\n",
    "  hits = 0\n",
    "  misses = 0\n",
    "\n",
    "  # Préparation de la matrice\n",
    "  # Les mots qui ne se trouvent pas dans les plongements pré-entraînés seront \n",
    "  # représentés par des vecteurs dont toutes les composantes sont égales à 0,\n",
    "  # y compris la représentation utilisée pour compléter les documents courts et\n",
    "  # celle utilisée pour les mots inconnus [UNK]\n",
    "  embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "  for word, i in word_index.items():\n",
    "      embedding_vector = embeddings_index.get(word)\n",
    "      if embedding_vector is not None:\n",
    "          embedding_matrix[i] = embedding_vector\n",
    "          hits += 1\n",
    "      else:\n",
    "          misses += 1\n",
    "  print(f'{hits} mots ont été trouvés dans les plongements pré-entraînés')\n",
    "  print(f'{misses} sont absents')\n",
    "  return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4468 mots ont été trouvés dans les plongements pré-entraînés\n",
      "3532 sont absents\n"
     ]
    }
   ],
   "source": [
    "# Construction de la matrice de plongements à partir du vocabulaire\n",
    "embedding_matrix = get_embedding_matrix(voc, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def get_biLSTM_model(voc_size, embedding_matrix, embedding_dim=700):\n",
    "  # Création du modèle\n",
    "  int_sequences_input = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "  embedding_layer = Embedding(voc_size, embedding_dim, trainable=True,\n",
    "      embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "  )\n",
    "  \n",
    "  embedded_sequences = embedding_layer(int_sequences_input)\n",
    "  x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, dropout=0.2, recurrent_dropout=0.2))(embedded_sequences)\n",
    "  preds = tf.keras.layers.Dense(len(genre_name), activation=\"softmax\")(x)\n",
    "  model = tf.keras.Model(int_sequences_input, preds)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 700)         5600000   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              391680    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,992,841\n",
      "Trainable params: 5,992,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Affichage de l'architecture du modèle\n",
    "biLSTM_model = get_biLSTM_model(len(voc), embedding_matrix)\n",
    "biLSTM_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from tensorflow.keras.callbacks import EarlyStopping # Early stopping to avoid over-fitting\n",
    "\n",
    "# Fonction pour l'entraînement d'un modèle\n",
    "def train_model(X, y, model_function, vectorizer, voc_size, embedding_matrix, embedding_dim=700, batch_size=64): # 128\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping_callback = EarlyStopping(monitor=\"val_acc\", restore_best_weights=True, patience=3)\n",
    "    \n",
    "    # Listes utilisées pour sauvegarder les résultats obtenus à chaque pli\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "    histories = []\n",
    "    folds = 5\n",
    "    stratkfold = model_selection.StratifiedKFold(n_splits=folds, shuffle=True, random_state=12)\n",
    "    fold_no = 1\n",
    "    for train, test in stratkfold.split(X, y):\n",
    "        m_function = globals()[model_function]\n",
    "        model = m_function(voc_size, embedding_matrix, embedding_dim)\n",
    "\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Entraînement pour le pli {fold_no} ...')\n",
    "        fold_x_train = vectorizer(X.iloc[train].to_numpy()).numpy()\n",
    "        fold_x_val = vectorizer(X.iloc[test].to_numpy()).numpy()\n",
    "        fold_y_train = y.iloc[train].to_numpy()\n",
    "        fold_y_val = y.iloc[test].to_numpy()\n",
    "\n",
    "        # Compilation du modèle : permet de préciser la fonction de perte et l'optimiseur\n",
    "        # loss=sparse_categorical_crossentropy : entropie croisée, dans le cas où les \n",
    "        # classes cibles sont indiquées sous forme d'entiers. Il s'agira de minimiser\n",
    "        # la perte pendant l'apprentissage\n",
    "        # optimizer=rmsprop : l'optimiseur détermine la manière doit les poids seront\n",
    "        # mis à jour pendant l'apprentissage\n",
    "        model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "        # Entraînement sur 10 époque (la totalité du jeu de données est parcourue\n",
    "        # 10 fois)\n",
    "        history = model.fit(fold_x_train, fold_y_train, batch_size=batch_size, epochs=25, validation_data=(fold_x_val, fold_y_val), callbacks=[early_stopping_callback])\n",
    "        histories.append(history)\n",
    "        # Evaluation sur les données de validation\n",
    "        scores = model.evaluate(fold_x_val, fold_y_val, verbose=0)\n",
    "        print(f'Scores pour le pli {fold_no}: {model.metrics_names[0]} = {scores[0]:.2f};',\n",
    "            f'{model.metrics_names[1]} = {scores[1]*100:.2f}%')\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "    # Affichage des scores moyens par pli\n",
    "    print('---------------------------------------------------------------------')\n",
    "    print('Scores par pli')\n",
    "    for i in range(0, len(acc_per_fold)):\n",
    "        print('---------------------------------------------------------------------')\n",
    "        print(f'> Pli {i+1} - Loss: {loss_per_fold[i]:.2f}', f'- Accuracy: {acc_per_fold[i]:.2f}%')\n",
    "    print('---------------------------------------------------------------------')\n",
    "    print('Scores moyens pour tous les plis :')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold):.2f}', f'(+- {np.std(acc_per_fold):.2f})')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold):.2f}')\n",
    "    print('---------------------------------------------------------------------')\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Entraînement pour le pli 1 ...\n",
      "Epoch 1/25\n",
      "57/57 [==============================] - 34s 551ms/step - loss: 1.9864 - acc: 0.2934 - val_loss: 1.8969 - val_acc: 0.3796\n",
      "Epoch 2/25\n",
      "57/57 [==============================] - 31s 552ms/step - loss: 1.5306 - acc: 0.5140 - val_loss: 1.7620 - val_acc: 0.3663\n",
      "Epoch 3/25\n",
      "57/57 [==============================] - 32s 553ms/step - loss: 1.2000 - acc: 0.6145 - val_loss: 1.1872 - val_acc: 0.5916\n",
      "Epoch 4/25\n",
      "57/57 [==============================] - 33s 576ms/step - loss: 0.9805 - acc: 0.6953 - val_loss: 1.0754 - val_acc: 0.6360\n",
      "Epoch 5/25\n",
      "57/57 [==============================] - 32s 554ms/step - loss: 0.8032 - acc: 0.7533 - val_loss: 1.0469 - val_acc: 0.6559\n",
      "Epoch 6/25\n",
      "57/57 [==============================] - 32s 553ms/step - loss: 0.6816 - acc: 0.7849 - val_loss: 0.9267 - val_acc: 0.6959\n",
      "Epoch 7/25\n",
      "57/57 [==============================] - 32s 554ms/step - loss: 0.5575 - acc: 0.8276 - val_loss: 1.0037 - val_acc: 0.6781\n",
      "Epoch 8/25\n",
      "57/57 [==============================] - 31s 553ms/step - loss: 0.4620 - acc: 0.8582 - val_loss: 0.8533 - val_acc: 0.7314\n",
      "Epoch 9/25\n",
      "57/57 [==============================] - 32s 556ms/step - loss: 0.3567 - acc: 0.8940 - val_loss: 1.0660 - val_acc: 0.6759\n",
      "Epoch 10/25\n",
      "57/57 [==============================] - 32s 554ms/step - loss: 0.2849 - acc: 0.9137 - val_loss: 1.0890 - val_acc: 0.6826\n",
      "Epoch 11/25\n",
      "57/57 [==============================] - 32s 555ms/step - loss: 0.2336 - acc: 0.9370 - val_loss: 1.1506 - val_acc: 0.6937\n",
      "Scores pour le pli 1: loss = 0.85; acc = 73.14%\n",
      "------------------------------------------------------------------------\n",
      "Entraînement pour le pli 2 ...\n",
      "Epoch 1/25\n",
      "57/57 [==============================] - 34s 559ms/step - loss: 1.9715 - acc: 0.3136 - val_loss: 1.9565 - val_acc: 0.2986\n",
      "Epoch 2/25\n",
      "57/57 [==============================] - 32s 555ms/step - loss: 1.5057 - acc: 0.5076 - val_loss: 1.4669 - val_acc: 0.4972\n",
      "Epoch 3/25\n",
      "57/57 [==============================] - 32s 555ms/step - loss: 1.1907 - acc: 0.6264 - val_loss: 1.3081 - val_acc: 0.5394\n",
      "Epoch 4/25\n",
      "57/57 [==============================] - 32s 562ms/step - loss: 0.9658 - acc: 0.6858 - val_loss: 1.3004 - val_acc: 0.5616\n",
      "Epoch 5/25\n",
      "57/57 [==============================] - 32s 567ms/step - loss: 0.7914 - acc: 0.7522 - val_loss: 1.1427 - val_acc: 0.6149\n",
      "Epoch 6/25\n",
      "57/57 [==============================] - 32s 566ms/step - loss: 0.6408 - acc: 0.7957 - val_loss: 1.0058 - val_acc: 0.6715\n",
      "Epoch 7/25\n",
      "57/57 [==============================] - 32s 566ms/step - loss: 0.5376 - acc: 0.8371 - val_loss: 1.0229 - val_acc: 0.6759\n",
      "Epoch 8/25\n",
      "57/57 [==============================] - 32s 566ms/step - loss: 0.4338 - acc: 0.8651 - val_loss: 1.0626 - val_acc: 0.6748\n",
      "Epoch 9/25\n",
      "57/57 [==============================] - 32s 568ms/step - loss: 0.3568 - acc: 0.8890 - val_loss: 1.0893 - val_acc: 0.6626\n",
      "Epoch 10/25\n",
      "57/57 [==============================] - 32s 565ms/step - loss: 0.3005 - acc: 0.9112 - val_loss: 0.9722 - val_acc: 0.7148\n",
      "Epoch 11/25\n",
      "57/57 [==============================] - 32s 564ms/step - loss: 0.2417 - acc: 0.9259 - val_loss: 1.0838 - val_acc: 0.7081\n",
      "Epoch 12/25\n",
      "57/57 [==============================] - 32s 566ms/step - loss: 0.2004 - acc: 0.9445 - val_loss: 1.0732 - val_acc: 0.7248\n",
      "Epoch 13/25\n",
      "57/57 [==============================] - 32s 570ms/step - loss: 0.1573 - acc: 0.9578 - val_loss: 1.0556 - val_acc: 0.7425\n",
      "Epoch 14/25\n",
      "57/57 [==============================] - 31s 536ms/step - loss: 0.1257 - acc: 0.9678 - val_loss: 1.0983 - val_acc: 0.7137\n",
      "Epoch 15/25\n",
      "57/57 [==============================] - 30s 524ms/step - loss: 0.0980 - acc: 0.9759 - val_loss: 1.1583 - val_acc: 0.7292\n",
      "Epoch 16/25\n",
      "57/57 [==============================] - 30s 530ms/step - loss: 0.0913 - acc: 0.9778 - val_loss: 1.1814 - val_acc: 0.7225\n",
      "Scores pour le pli 2: loss = 1.06; acc = 74.25%\n",
      "------------------------------------------------------------------------\n",
      "Entraînement pour le pli 3 ...\n",
      "Epoch 1/25\n",
      "57/57 [==============================] - 33s 541ms/step - loss: 2.0027 - acc: 0.3100 - val_loss: 1.7182 - val_acc: 0.4129\n",
      "Epoch 2/25\n",
      "57/57 [==============================] - 30s 535ms/step - loss: 1.4747 - acc: 0.5287 - val_loss: 1.3494 - val_acc: 0.5361\n",
      "Epoch 3/25\n",
      "57/57 [==============================] - 31s 536ms/step - loss: 1.1237 - acc: 0.6386 - val_loss: 1.2685 - val_acc: 0.5605\n",
      "Epoch 4/25\n",
      "57/57 [==============================] - 33s 576ms/step - loss: 0.8967 - acc: 0.7127 - val_loss: 1.2230 - val_acc: 0.5760\n",
      "Epoch 5/25\n",
      "57/57 [==============================] - 36s 633ms/step - loss: 0.7453 - acc: 0.7585 - val_loss: 1.0314 - val_acc: 0.6626\n",
      "Epoch 6/25\n",
      "57/57 [==============================] - 33s 582ms/step - loss: 0.5893 - acc: 0.8129 - val_loss: 1.1287 - val_acc: 0.6304\n",
      "Epoch 7/25\n",
      "57/57 [==============================] - 30s 532ms/step - loss: 0.5058 - acc: 0.8354 - val_loss: 0.9730 - val_acc: 0.6926\n",
      "Epoch 8/25\n",
      "57/57 [==============================] - 30s 532ms/step - loss: 0.4055 - acc: 0.8795 - val_loss: 0.9203 - val_acc: 0.7003\n",
      "Epoch 9/25\n",
      "57/57 [==============================] - 32s 559ms/step - loss: 0.3375 - acc: 0.8965 - val_loss: 0.9476 - val_acc: 0.7192\n",
      "Epoch 10/25\n",
      "57/57 [==============================] - 30s 532ms/step - loss: 0.2758 - acc: 0.9195 - val_loss: 1.1146 - val_acc: 0.6748\n",
      "Epoch 11/25\n",
      "57/57 [==============================] - 31s 535ms/step - loss: 0.2146 - acc: 0.9389 - val_loss: 0.9549 - val_acc: 0.7314\n",
      "Epoch 12/25\n",
      "57/57 [==============================] - 31s 542ms/step - loss: 0.1885 - acc: 0.9442 - val_loss: 1.0572 - val_acc: 0.7026\n",
      "Epoch 13/25\n",
      "57/57 [==============================] - 31s 536ms/step - loss: 0.1359 - acc: 0.9642 - val_loss: 1.0597 - val_acc: 0.7148\n",
      "Epoch 14/25\n",
      "57/57 [==============================] - 31s 537ms/step - loss: 0.1186 - acc: 0.9664 - val_loss: 1.1178 - val_acc: 0.7225\n",
      "Scores pour le pli 3: loss = 0.95; acc = 73.14%\n",
      "------------------------------------------------------------------------\n",
      "Entraînement pour le pli 4 ...\n",
      "Epoch 1/25\n",
      "57/57 [==============================] - 33s 541ms/step - loss: 1.9940 - acc: 0.3109 - val_loss: 1.7429 - val_acc: 0.4018\n",
      "Epoch 2/25\n",
      "57/57 [==============================] - 31s 539ms/step - loss: 1.4815 - acc: 0.5140 - val_loss: 1.4171 - val_acc: 0.5172\n",
      "Epoch 3/25\n",
      "57/57 [==============================] - 31s 538ms/step - loss: 1.1658 - acc: 0.6178 - val_loss: 1.2718 - val_acc: 0.5616\n",
      "Epoch 4/25\n",
      "57/57 [==============================] - 31s 542ms/step - loss: 0.9464 - acc: 0.6958 - val_loss: 1.3094 - val_acc: 0.5327\n",
      "Epoch 5/25\n",
      "57/57 [==============================] - 31s 538ms/step - loss: 0.7750 - acc: 0.7502 - val_loss: 0.9628 - val_acc: 0.6815\n",
      "Epoch 6/25\n",
      "57/57 [==============================] - 31s 538ms/step - loss: 0.6252 - acc: 0.8063 - val_loss: 0.9445 - val_acc: 0.7048\n",
      "Epoch 7/25\n",
      "57/57 [==============================] - 31s 538ms/step - loss: 0.5133 - acc: 0.8351 - val_loss: 0.8855 - val_acc: 0.7181\n",
      "Epoch 8/25\n",
      "57/57 [==============================] - 31s 538ms/step - loss: 0.4133 - acc: 0.8770 - val_loss: 0.9967 - val_acc: 0.7037\n",
      "Epoch 9/25\n",
      "57/57 [==============================] - 31s 544ms/step - loss: 0.3442 - acc: 0.8940 - val_loss: 0.8195 - val_acc: 0.7469\n",
      "Epoch 10/25\n",
      "57/57 [==============================] - 31s 537ms/step - loss: 0.2789 - acc: 0.9165 - val_loss: 0.8564 - val_acc: 0.7580\n",
      "Epoch 11/25\n",
      "57/57 [==============================] - 31s 538ms/step - loss: 0.2263 - acc: 0.9345 - val_loss: 0.8510 - val_acc: 0.7592\n",
      "Epoch 12/25\n",
      "57/57 [==============================] - 31s 539ms/step - loss: 0.1816 - acc: 0.9525 - val_loss: 0.8867 - val_acc: 0.7592\n",
      "Epoch 13/25\n",
      "57/57 [==============================] - 31s 537ms/step - loss: 0.1459 - acc: 0.9614 - val_loss: 0.9986 - val_acc: 0.7547\n",
      "Epoch 14/25\n",
      "57/57 [==============================] - 31s 541ms/step - loss: 0.1148 - acc: 0.9711 - val_loss: 0.9104 - val_acc: 0.7725\n",
      "Epoch 15/25\n",
      "57/57 [==============================] - 31s 545ms/step - loss: 0.0962 - acc: 0.9734 - val_loss: 0.9550 - val_acc: 0.7714\n",
      "Epoch 16/25\n",
      "57/57 [==============================] - 31s 541ms/step - loss: 0.0627 - acc: 0.9858 - val_loss: 1.1010 - val_acc: 0.7636\n",
      "Epoch 17/25\n",
      "57/57 [==============================] - 31s 538ms/step - loss: 0.0670 - acc: 0.9836 - val_loss: 0.9859 - val_acc: 0.7758\n",
      "Epoch 18/25\n",
      "57/57 [==============================] - 31s 538ms/step - loss: 0.0473 - acc: 0.9895 - val_loss: 1.1851 - val_acc: 0.7425\n",
      "Epoch 19/25\n",
      "57/57 [==============================] - 31s 544ms/step - loss: 0.0483 - acc: 0.9906 - val_loss: 0.9953 - val_acc: 0.7791\n",
      "Epoch 20/25\n",
      "57/57 [==============================] - 31s 538ms/step - loss: 0.0352 - acc: 0.9922 - val_loss: 1.1190 - val_acc: 0.7680\n",
      "Epoch 21/25\n",
      "57/57 [==============================] - 31s 545ms/step - loss: 0.0291 - acc: 0.9931 - val_loss: 1.2122 - val_acc: 0.7703\n",
      "Epoch 22/25\n",
      "57/57 [==============================] - 31s 536ms/step - loss: 0.0334 - acc: 0.9928 - val_loss: 1.2005 - val_acc: 0.7725\n",
      "Scores pour le pli 4: loss = 1.00; acc = 77.91%\n",
      "------------------------------------------------------------------------\n",
      "Entraînement pour le pli 5 ...\n",
      "Epoch 1/25\n",
      "57/57 [==============================] - 33s 540ms/step - loss: 1.9711 - acc: 0.3069 - val_loss: 1.7041 - val_acc: 0.4389\n",
      "Epoch 2/25\n",
      "57/57 [==============================] - 31s 535ms/step - loss: 1.4449 - acc: 0.5258 - val_loss: 1.4053 - val_acc: 0.5122\n",
      "Epoch 3/25\n",
      "57/57 [==============================] - 31s 539ms/step - loss: 1.1631 - acc: 0.6276 - val_loss: 1.2731 - val_acc: 0.5856\n",
      "Epoch 4/25\n",
      "57/57 [==============================] - 32s 570ms/step - loss: 0.9659 - acc: 0.7001 - val_loss: 1.1594 - val_acc: 0.5922\n",
      "Epoch 5/25\n",
      "57/57 [==============================] - 31s 545ms/step - loss: 0.7916 - acc: 0.7483 - val_loss: 1.0274 - val_acc: 0.6722\n",
      "Epoch 6/25\n",
      "57/57 [==============================] - 30s 533ms/step - loss: 0.6595 - acc: 0.7922 - val_loss: 1.0267 - val_acc: 0.6600\n",
      "Epoch 7/25\n",
      "57/57 [==============================] - 30s 532ms/step - loss: 0.5472 - acc: 0.8277 - val_loss: 0.9507 - val_acc: 0.6878\n",
      "Epoch 8/25\n",
      "57/57 [==============================] - 30s 532ms/step - loss: 0.4377 - acc: 0.8654 - val_loss: 1.0903 - val_acc: 0.6589\n",
      "Epoch 9/25\n",
      "57/57 [==============================] - 30s 533ms/step - loss: 0.3819 - acc: 0.8785 - val_loss: 0.9724 - val_acc: 0.7033\n",
      "Epoch 10/25\n",
      "57/57 [==============================] - 30s 532ms/step - loss: 0.3001 - acc: 0.9151 - val_loss: 1.0389 - val_acc: 0.7000\n",
      "Epoch 11/25\n",
      "57/57 [==============================] - 30s 535ms/step - loss: 0.2406 - acc: 0.9276 - val_loss: 1.0111 - val_acc: 0.7289\n",
      "Epoch 12/25\n",
      "57/57 [==============================] - 30s 533ms/step - loss: 0.2085 - acc: 0.9415 - val_loss: 1.0287 - val_acc: 0.7389\n",
      "Epoch 13/25\n",
      "57/57 [==============================] - 30s 532ms/step - loss: 0.1611 - acc: 0.9584 - val_loss: 1.0562 - val_acc: 0.7211\n",
      "Epoch 14/25\n",
      "57/57 [==============================] - 30s 534ms/step - loss: 0.1375 - acc: 0.9667 - val_loss: 1.1243 - val_acc: 0.7244\n",
      "Epoch 15/25\n",
      "57/57 [==============================] - 30s 533ms/step - loss: 0.1188 - acc: 0.9714 - val_loss: 1.1088 - val_acc: 0.7411\n",
      "Epoch 16/25\n",
      "57/57 [==============================] - 30s 532ms/step - loss: 0.0907 - acc: 0.9775 - val_loss: 1.2161 - val_acc: 0.7356\n",
      "Epoch 17/25\n",
      "57/57 [==============================] - 30s 534ms/step - loss: 0.0826 - acc: 0.9800 - val_loss: 1.2541 - val_acc: 0.7211\n",
      "Epoch 18/25\n",
      "57/57 [==============================] - 31s 536ms/step - loss: 0.0594 - acc: 0.9861 - val_loss: 1.2112 - val_acc: 0.7367\n",
      "Scores pour le pli 5: loss = 1.11; acc = 74.11%\n",
      "---------------------------------------------------------------------\n",
      "Scores par pli\n",
      "---------------------------------------------------------------------\n",
      "> Pli 1 - Loss: 0.85 - Accuracy: 73.14%\n",
      "---------------------------------------------------------------------\n",
      "> Pli 2 - Loss: 1.06 - Accuracy: 74.25%\n",
      "---------------------------------------------------------------------\n",
      "> Pli 3 - Loss: 0.95 - Accuracy: 73.14%\n",
      "---------------------------------------------------------------------\n",
      "> Pli 4 - Loss: 1.00 - Accuracy: 77.91%\n",
      "---------------------------------------------------------------------\n",
      "> Pli 5 - Loss: 1.11 - Accuracy: 74.11%\n",
      "---------------------------------------------------------------------\n",
      "Scores moyens pour tous les plis :\n",
      "> Accuracy: 74.51 (+- 1.76)\n",
      "> Loss: 0.99\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Entraînement du modèle et récupération des résultats\n",
    "biLSTM_histories = train_model(X_train, y_train, 'get_biLSTM_model', vectorizer, len(voc), embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "def plot_results(histories):\n",
    "    accuracy_data = []\n",
    "    loss_data = []\n",
    "    for i, h in enumerate(histories):\n",
    "        acc = h.history['acc']\n",
    "        val_acc = h.history['val_acc']\n",
    "        loss = h.history['loss']\n",
    "        val_loss = h.history['val_loss']\n",
    "        for j in range(len(acc)):\n",
    "            accuracy_data.append([i+1, j+1, acc[j], 'Entraînement'])\n",
    "            accuracy_data.append([i+1, j+1, val_acc[j], 'Validation'])\n",
    "            loss_data.append([i+1, j+1, loss[j], 'Entraînement'])\n",
    "            loss_data.append([i+1, j+1, val_loss[j], 'Validation'])\n",
    "\n",
    "    acc_df = pd.DataFrame(accuracy_data, columns=['Pli', 'Epoch', 'Accuracy', 'Données'])\n",
    "    sns.relplot(data=acc_df, x='Epoch', y='Accuracy', hue='Pli', style='Données', kind='line')\n",
    "    \n",
    "    loss_df = pd.DataFrame(loss_data, columns=['Pli', 'Epoch', 'Perte', 'Données'])\n",
    "    sns.relplot(data=loss_df, x='Epoch', y='Perte', hue='Pli', style='Données', kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(CNN_histories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
