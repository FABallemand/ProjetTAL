\section{Transformer}
Les transformers sont des modèles de réseaux de neurones permettant la prise en compte de dépendance à très grande distance grâce à un mécanisme d'auto-attention.\\
Pour des tâches complexes cet entraînement requiert une grande quantité de données ainsi qu'une grande puissance de calcul afin d'obtenir des résultats corrects. Pour éviter cette phase d'entraînement, on peut utiliser un modèle déjà entraîné et l'adapter aux données et à l'objectif souhaité.\\
Le site Hugging Face \cite{hugging_face} recense de nombreux modèles pré-entraînés en fonction de la langue et de la tâche.\\
Malheureusement, que ce soit en local ou en utilisant Google Colab, nous n'avons pas trouvé de modèle français pouvant être entraîné...