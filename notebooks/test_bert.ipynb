{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# better display of review text in dataframes\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "\n",
    "# Seaborn options\n",
    "sns.set(style=\"whitegrid\", font_scale=1.4)\n",
    "\n",
    "# Auto reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# PICKLE_PATH = \"allocine_dataset/data/allocine_dataset.pickle\"\n",
    "\n",
    "# with open(PICKLE_PATH, 'rb') as reader:\n",
    "#     data = pickle.load(reader)\n",
    "\n",
    "# # Reviews need to be tokenized\n",
    "# train_reviews = np.array(data[\"train_set\"]['review'])\n",
    "# val_reviews = np.array(data[\"val_set\"]['review'])\n",
    "# test_reviews = np.array(data[\"test_set\"]['review'])\n",
    "\n",
    "# train_labels = data[\"train_set\"]['polarity']\n",
    "# val_labels = data[\"val_set\"]['polarity']\n",
    "# test_labels = data[\"test_set\"]['polarity']\n",
    "# class_names = data['class_names']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer\n",
    "\n",
    "model_name = \"camembert-base\"\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_review = train_reviews[0]\n",
    "some_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer.tokenize(some_review)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer.encode(some_review)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenizer.encode(some_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_len = [len(tokenizer.encode(review, max_length=512))\n",
    "                          for review in train_reviews]\n",
    "print(\"Average length: {:.1f}\".format(np.mean(reviews_len)))\n",
    "print(\"Max length: {}\".format(max(reviews_len)))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = sns.distplot(reviews_len, bins=150, kde=False, hist_kws=dict(alpha=0.8))\n",
    "ax.set(xlabel='Number of tokens')\n",
    "\n",
    "# Finalize the plot\n",
    "sns.despine(bottom=True)\n",
    "plt.tight_layout(h_pad=2)\n",
    "\n",
    "# Saving plot\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('img/bert/number_of_tokens.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 400 # in terms of generated tokens (not words)\n",
    "\n",
    "short_reviews = sum(np.array(reviews_len) <= MAX_SEQ_LEN)\n",
    "long_reviews = sum(np.array(reviews_len) > MAX_SEQ_LEN)\n",
    "\n",
    "print(\"{} reviews with LEN > {} ({:.2f} % of total data)\".format(\n",
    "    long_reviews,\n",
    "    MAX_SEQ_LEN,\n",
    "    100 * long_reviews / len(reviews_len)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def encode_reviews(tokenizer, reviews, max_length):\n",
    "    token_ids = np.zeros(shape=(len(reviews), max_length),\n",
    "                         dtype=np.int32)\n",
    "    for i, review in enumerate(reviews):\n",
    "        encoded = tokenizer.encode(review, max_length=max_length)\n",
    "        token_ids[i, 0:len(encoded)] = encoded\n",
    "    attention_mask = (token_ids != 0).astype(np.int32)\n",
    "    return {\"input_ids\": token_ids, \"attention_mask\": attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train = encode_reviews(tokenizer, train_reviews, MAX_SEQ_LEN)\n",
    "encoded_valid = encode_reviews(tokenizer, val_reviews, MAX_SEQ_LEN)\n",
    "encoded_test = encode_reviews(tokenizer, test_reviews, MAX_SEQ_LEN)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CamembertPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def fit(self, X=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y):\n",
    "        # 1. Tokenize\n",
    "        X_encoded = encode_reviews(self.tokenizer, X, self.max_seq_length)\n",
    "        # 2. Labels\n",
    "        y_array = np.array(y)\n",
    "        return X_encoded, y_array     \n",
    "    \n",
    "    def fit_transform(self, X, y):        \n",
    "        return self.transform(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFCamembertForSequenceClassification\n",
    "\n",
    "model = TFCamembertForSequenceClassification.from_pretrained(\"jplu/tf-camembert-base\")\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-6, epsilon=1e-08)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)    \n",
    "\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = model.get_weights()\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (in fact, done in the Accuracy vs Training Data part)\n",
    "history = model.fit(\n",
    "    encoded_train, y_train, epochs=1, batch_size=4, \n",
    "    validation_data=(encoded_valid, y_val), verbose=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy vs Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class EarlyStoppingModel(BaseEstimator):\n",
    "    def __init__(self, transformers_model, max_epoches, batch_size, validation_data):\n",
    "        self.model = transformers_model\n",
    "        self.max_epoches = max_epoches\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_data = validation_data\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        # Defines early stopper\n",
    "        early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', mode='auto', patience=2, # only 1 !\n",
    "            verbose=1, restore_best_weights=True\n",
    "        )        \n",
    "\n",
    "        # Train model on data subset\n",
    "        self.model.fit(\n",
    "            X, y,\n",
    "            validation_data=self.validation_data,\n",
    "            epochs=self.max_epoches, \n",
    "            batch_size=self.batch_size,\n",
    "            callbacks=[early_stopper], \n",
    "            verbose=1\n",
    "        )        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):        \n",
    "        scores = self.model.predict(X)\n",
    "        y_pred = np.argmax(scores, axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "def accuracy_vs_training_data(camembert_model, initial_weights, \n",
    "                              preprocessor, sizes,\n",
    "                              train_reviews, train_labels,\n",
    "                              val_reviews, val_labels,\n",
    "                              test_reviews, test_labels):\n",
    "    test_accuracies = []\n",
    "    for size in sizes:        \n",
    "        # Preprocess data\n",
    "        X_train, y_train = preprocessor.fit_transform(\n",
    "            train_reviews[:size], train_labels[:size]\n",
    "        )\n",
    "        X_val, y_val = preprocessor.transform(val_reviews, val_labels)\n",
    "        X_test, y_test = preprocessor.transform(test_reviews, test_labels)\n",
    "        \n",
    "        # Reset weights to initial value\n",
    "        camembert_model.set_weights(initial_weights)\n",
    "        best_model = EarlyStoppingModel(\n",
    "            camembert_model, max_epoches=20, batch_size=4,\n",
    "            validation_data=(X_val, y_val)\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        test_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "        test_accuracies.append(test_acc)\n",
    "        print(\"Test acc: \" + str(test_acc))\n",
    "        \n",
    "    return test_accuracies    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [int(p) for p in np.geomspace(500, 160000, 5)]\n",
    "preprocessor = CamembertPreprocessor(tokenizer, MAX_SEQ_LEN)\n",
    "\n",
    "test_accuracies = accuracy_vs_training_data(\n",
    "    model, initial_weights, \n",
    "    preprocessor, sizes,\n",
    "    train_reviews, train_labels,\n",
    "    val_reviews, val_labels,\n",
    "    test_reviews, test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving last model (full dataset)\n",
    "model.save_weights('data/bert/camembert_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "OUTPUT_PATH = 'data/bert/camembert_accuracies.pickle'\n",
    "\n",
    "output_dict = {\n",
    "    \"sizes\": sizes,\n",
    "    \"test_accuracies\": test_accuracies\n",
    "}\n",
    "\n",
    "with open(OUTPUT_PATH, 'wb') as writer:\n",
    "    pickle.dump(output_dict, writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "model.load_weights('data/camembert_weights.hdf5')\n",
    "scores = model.predict(encoded_valid)\n",
    "y_pred = np.argmax(scores, axis=1)\n",
    "    \n",
    "print(\"Val Accuracy: {:.2f}\".format(100 * metrics.accuracy_score(y_val, y_pred)))\n",
    "print(\"Val F1-Score: {:.2f}\".format(100 * metrics.f1_score(y_val, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import print_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mx = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "fig = print_confusion_matrix(\n",
    "    conf_mx, \n",
    "    class_names.values(), \n",
    "    figsize=(7,5)\n",
    ")\n",
    "\n",
    "# Finalize the plot\n",
    "sns.despine(bottom=True)\n",
    "plt.tight_layout(h_pad=2)\n",
    "\n",
    "# Saving plot\n",
    "fig.savefig('img/bert/val_confusion_mx.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## False positive / negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos = val_reviews[(y_val == 0) & (y_pred == 1)]\n",
    "false_neg = val_reviews[(y_val == 1) & (y_pred == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(false_pos[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(false_neg[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('data/bert/camembert_weights.hdf5')\n",
    "\n",
    "scores = model.predict(encoded_test)\n",
    "y_pred = np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "    \n",
    "print(\"Test Accuracy: {:.2f}\".format(100 * metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"Test F1-Score: {:.2f}\".format(100 * metrics.f1_score(y_test, y_pred)))\n",
    "print()\n",
    "\n",
    "report = metrics.classification_report(\n",
    "    y_test, y_pred, \n",
    "    target_names=class_names.values()\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mx = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig = print_confusion_matrix(\n",
    "    conf_mx, \n",
    "    class_names.values(), \n",
    "    figsize=(7,5)\n",
    ")\n",
    "\n",
    "# Finalize the plot\n",
    "sns.despine(bottom=True)\n",
    "plt.tight_layout(h_pad=2)\n",
    "\n",
    "# Saving plot\n",
    "fig.savefig('img/bert/test_confusion_mx.png', dpi=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('data/bert/camembert_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "inference_times = []\n",
    "\n",
    "for i in range(1000):\n",
    "    x = {\n",
    "    'input_ids': np.array([encoded_test['input_ids'][i], ]),\n",
    "    'attention_mask':  np.array([encoded_test['attention_mask'][i], ]),\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(x)\n",
    "    stop_time = time.time()\n",
    "    \n",
    "    inference_times.append(stop_time - start_time)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/bert/camembert_times.pickle'\n",
    "\n",
    "with open(OUTPUT_PATH, 'wb') as writer:\n",
    "    pickle.dump(inference_times, writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalizability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils_acl import get_data\n",
    "\n",
    "ACL_FOLDER = 'data/cls-acl10-unprocessed/fr'\n",
    "BOOKS_FOLDER = os.path.join(ACL_FOLDER, 'books')\n",
    "DVD_FOLDER = os.path.join(ACL_FOLDER, 'dvd')\n",
    "MUSIC_FOLDER = os.path.join(ACL_FOLDER, 'music')\n",
    "\n",
    "_, _, test_reviews_b, test_labels_b = get_data(BOOKS_FOLDER)\n",
    "_, _, test_reviews_d, test_labels_d  = get_data(DVD_FOLDER)\n",
    "_, _, test_reviews_m, test_labels_m  = get_data(MUSIC_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "def evaluate(model, X, y):\n",
    "    scores = model.predict(X)\n",
    "    y_pred = np.argmax(scores, axis=1)\n",
    "    print(\"Accuracy: {:.2f}\".format(100 * metrics.accuracy_score(y, y_pred)))\n",
    "    print(\"F1-Score: {:.2f}\".format(100 * metrics.f1_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = CamembertPreprocessor(tokenizer, MAX_SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('data/bert/camembert_weights.hdf5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_books, y_books = preprocessor.transform(test_reviews_b, test_labels_b)\n",
    "evaluate(model, X_books, y_books)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dvd, y_dvd = preprocessor.transform(test_reviews_d, test_labels_d)\n",
    "evaluate(model, X_dvd, y_dvd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_music, y_music = preprocessor.transform(test_reviews_m, test_labels_m)\n",
    "evaluate(model, X_music, y_music)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
