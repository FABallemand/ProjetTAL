{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download\n",
    "download('stopwords')\n",
    "stopWords = set(stopwords.words('french'))\n",
    "print(stopWords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Premières Méthodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données d'entrainement\n",
    "train_data_complete = pd.read_csv(\"../data/allocine_genres_train.csv\", sep=\",\")\n",
    "train_data = train_data_complete[[\"titre\", \"synopsis\", \"genre\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-traitement des Données (Equilibrage des classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence) :\n",
    "    list_w = nlp(sentence)\n",
    "    list_w_clean = []\n",
    "    res = []\n",
    "    for token in list_w:\n",
    "        if (token.text.lower() not in stopWords) and (token.text not in [\"'\",'-',',','.','…','...',':',';']):\n",
    "            list_w_clean.append(token)\n",
    "    for token in list_w_clean:\n",
    "        res.append(token.lemma_.lower())\n",
    "    print(res)\n",
    "    return \" \".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop('genre', axis=1)\n",
    "y = train_data['genre']\n",
    "\n",
    "# Initialize the RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "#ros = RandomUnderSampler()\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X['titre'][i] = preprocess(X['titre'][i])\n",
    "    X['synopsis'][i] = preprocess(X['synopsis'][i])\n",
    "# Perform oversampling\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Convert the resampled data back to a DataFrame\n",
    "train_data = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='genre')], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-Traitement des Données (Pipeline statistique)\n",
    "\n",
    "Comme vu précédemment, les paramètres que nous souhaitons utiliser (*titre*, *synopsis*, *genre*) ne comportent **pas de valeurs manquantes** donc nous n'avons pas besoin d'éliminer d'individus des données d'entrainement.\n",
    "\n",
    "Nous remarquons aussi que **les données sont déjà tokénisées**. Tous les tokens sont séparés par des espaces.\n",
    "\n",
    "Cependant, nous pouvons utiliser un transformer pour obtenir des informations statistiques concernant le *synopsis*.\n",
    "\n",
    "**Remarque:** On normalise ces informations statistiques afin qu'elles aient toutes le même poids lors de la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as en_stop\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def transform_into_token_list(synopsis):\n",
    "    return synopsis.split(\" \")\n",
    "\n",
    "# Vectorisation des titres\n",
    "title_stopwords = list(fr_stop) + list(en_stop) + list(string.punctuation)\n",
    "titre_vectorizer = TfidfVectorizer(tokenizer=transform_into_token_list, \n",
    "                                   lowercase=True, \n",
    "                                   stop_words=title_stopwords, \n",
    "                                   min_df=0.01)\n",
    "\n",
    "# Vectorisation des synopsis\n",
    "synopsis_stopwords = list(fr_stop) + list(string.punctuation)\n",
    "synopsis_vectorizer = TfidfVectorizer(tokenizer=transform_into_token_list, \n",
    "                                      lowercase=True, \n",
    "                                      stop_words=synopsis_stopwords, \n",
    "                                      min_df=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synopsis_stopwords[:15]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En tant qu'humain, certains stop words nous semblent importants..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler\n",
    "\n",
    "# Source: https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer.html\n",
    "def text_stats(descriptions):\n",
    "    return [{\"length\": len(text), \"num_sentences\": text.count(\".\")} for text in descriptions]\n",
    "\n",
    "text_stats_transformer = FunctionTransformer(text_stats)\n",
    "text_stats_vectorizer = DictVectorizer(sparse=False)\n",
    "\n",
    "# Exemple d'utilisation sur les premiers synopsis\n",
    "res_dict = text_stats_transformer.transform(train_data.synopsis.head())\n",
    "res_stats = text_stats_vectorizer.fit_transform(res_dict)\n",
    "print(\"Input descriptions\")\n",
    "print(train_data.synopsis.head())\n",
    "print(\"Output statistics\")\n",
    "stats = pd.DataFrame(res_stats, columns=text_stats_vectorizer.get_feature_names())\n",
    "print(stats)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "scaled_stats = min_max_scaler.fit_transform(res_stats)\n",
    "\n",
    "print(\"Before MinMax scaling\")\n",
    "print(res_stats)\n",
    "print(\"After MinMax scaling\")\n",
    "print(scaled_stats)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation de *MinMaxScaler* permet de ne pas donner plus de poids à l'une des valeurs obtenues, ce qui pourrait affecter la classification.\n",
    "\n",
    "On peut créer une *Pipeline* qui effectue l'ensemble des transformation sur le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "column_trans = ColumnTransformer(\n",
    "    [\n",
    "        # Titre: tf-idf\n",
    "        (\"titre_tfidf\", titre_vectorizer, \"titre\"),\n",
    "        # Synopsis: tf-idf\n",
    "        (\"synopsis_tfidf\", synopsis_vectorizer, \"synopsis\"),\n",
    "        # Synopsis: statistiques\n",
    "        (\n",
    "            \"synopsis_stats\",\n",
    "            Pipeline(\n",
    "                [\n",
    "                    (\"text_stats\", text_stats_transformer),\n",
    "                    (\"vect\", text_stats_vectorizer),\n",
    "                    (\"scaling\", min_max_scaler)\n",
    "                ]\n",
    "            ), \n",
    "            \"synopsis\"\n",
    "        )\n",
    "    ],\n",
    "    # Others\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des Jeux d'Entrainement et de Test\n",
    "\n",
    "Afin de ne pas biaiser le résultat de nos recherches nous n'utiliserons le fichier *allocine_genres_test.csv* uniquement lorsque nous aurons définitivement choisit le classifier. Nous n'utiliserons donc pas *test_data_complete* et *test_data* dans cette section.\n",
    "\n",
    "Afin de tester et évaluer différents algorithmes nous devons donc créer des jeux de données d'entrainement et de test issus des données d'entrainement (*train_data*). Pour cela nous utilisons la fonction *train_test_split* de la librairie **scikit-learn** en choisissant 20% des données pour créer le jeu de test en prenant soin de mélanger les données (cela perment d'éviter tout biais d'apprentissage: entrainer le classifier unioquement sur les films du XXème siècle).\n",
    "\n",
    "Nous obtenons donc 4 jeux de données:\n",
    "- X_train: Titre et synopsis pour entrainement  \n",
    "- y_train: Genre pour entrainement (label)  \n",
    "- X_test: Titre et synopsis pour test  \n",
    "- y_test: Genre pour test (label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data[[\"titre\", \"synopsis\"]],\n",
    "                                                    train_data[[\"genre\"]],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=12, # Random seed for shuffle\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Pipeline pré-traitement et apprentissage\n",
    "classifier_pipeline = make_pipeline(\n",
    "    # Préparation des données pour l'apprentissage\n",
    "    column_trans,\n",
    "    # Algorithme d'apprentissage\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage avec les données d'entraînement\n",
    "classifier_pipeline.fit(X_train, y_train.to_numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour le pré-traitement des données, on peut créer une *pipeline* qui regroupe les actions nécessaire à l'apprentissage (pré-traitement et apprentissage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = classifier_pipeline.predict(X_test)\n",
    "print(\"Classification report:\\n\\n{}\".format(classification_report(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La précision du classifier est proche de 0.5, ce qui est plutôt faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Liste des labels (classes) se trouvant dans les données de test\n",
    "labels = np.unique(y_test)\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "# Matrice de confusion sous forme de DataFrame\n",
    "confusion_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "print('confusion matrix\\n')\n",
    "print('(row=expected, col=predicted)')\n",
    "confusion_df.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() \n",
    "ax = fig.add_subplot(111) \n",
    "cax = ax.matshow(cm, interpolation='nearest', cmap=plt.cm.Oranges) \n",
    "fig.colorbar(cax) \n",
    "tick_marks = np.arange(len(labels))\n",
    "labels_for_fig = [l[0:5]+'.' for l in labels]\n",
    "plt.xticks(tick_marks, labels_for_fig, rotation=45)\n",
    "plt.yticks(tick_marks, labels_for_fig) \n",
    "plt.xlabel('Predicted') \n",
    "plt.ylabel('Expected') \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion permet de mieux comprendre les résultats.\n",
    "\n",
    "On remarque que le classifieur se trompe plus sur les données qui sont peu représentées dans le jeu de données (*biopic*, *documentaire*, *histoire*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df.loc['biopic'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "folds = 5\n",
    "\n",
    "stratkfold = model_selection.StratifiedKFold(n_splits=folds, shuffle=True, random_state=12)\n",
    "y_stratkfold_pred = model_selection.cross_val_predict(classifier_pipeline, X_train, y_train.values.flatten(), cv=stratkfold, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_stratkfold_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant une méthode de validation croisée qui conserve la proportion des classes dans les plis nous obtenons des résultats du même ordre (précision entre 0.4 et 0.5)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison des Différents Algorithmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Liste des modèles testés\n",
    "models = [\n",
    "    ('Baseline', DummyClassifier(strategy='most_frequent')),\n",
    "    ('Mutinomial NB', MultinomialNB()),\n",
    "    ('CART', DecisionTreeClassifier()),\n",
    "    ('LR', LogisticRegression()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Random forest', RandomForestClassifier())\n",
    "]\n",
    "\n",
    "# Evaluation de chaque résultat l'un après l'autre\n",
    "scores = []\n",
    "names = []\n",
    "scoring = 'macro F1'\n",
    "# Validation croisée à 5 plis\n",
    "kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\n",
    "# Itération sur les modèles\n",
    "for name, model in models:\n",
    "    # Ajout du nom du modèle à la liste name\n",
    "    names.append(name)\n",
    "    # Création de la pipeline pour le modèle\n",
    "    model_pipeline = make_pipeline(column_trans, model)\n",
    "    # Validation croisée\n",
    "    y_pred = model_selection.cross_val_predict(model_pipeline, X_train, y_train.values.flatten(), cv=kfold)\n",
    "    print(name)\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    f1 = f1_score(y_train, y_pred, average='macro')\n",
    "    scores.append(f1)\n",
    "\n",
    "# Représentation graphique des résultats\n",
    "indices = np.arange(len(scores))\n",
    "fig = plt.figure()\n",
    "plt.barh(indices, scores, .2, label=\"score\", color='b')\n",
    "plt.yticks(())\n",
    "for i, c in zip(indices, names):\n",
    "    plt.text(-.3, i, c)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
